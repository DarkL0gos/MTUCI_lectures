\section{Линейные пространства}
Напомним определение. В векторном пространстве $L$ над полем $P$ заданы две
операции: сложение, удовлетворяющее аксиомам абелевой группы: $\forall \Vec{x},
\Vec{y}, \Vec{z} \in L$\\
$1^0$. $\Vec{x}+\Vec{y}=\Vec{y}+\Vec{x}$\\
$2^0$. $(\Vec{x}+\Vec{y})+\Vec{y}=\Vec{x}+(\Vec{y}+\Vec{z})$\\
$3^0$. $\exists \Vec{0}: \Vec{x}+\Vec{0}=\Vec{x}$\\
$4^0$. $\exists \Vec{x'}: \Vec{x}+\Vec{x'}=\Vec{0}$\\
И умножение на скаляры из поля $P$ (чаще всего - вещественные или комплексные
числа): $\forall \Vec{x},\Vec{y}\in L \quad\forall \lambda_1,\lambda_2 \in P$\\
$5^0$. $(\lambda_1+\lambda_2)\Vec{x}=\lambda_1\Vec{x}+\lambda_2\Vec{x} $\\
$6^0$. $(\Vec{x}+\Vec{y})\lambda=\Vec{x}\lambda+\Vec{y}\lambda $\\
$7^0$. $\lambda_1(\lambda_2\Vec{x})=(\lambda_1\lambda_2)\Vec{x}$\\
$8^0$. $\exists 1\in P: 1\Vec{x}=\Vec{x}$\\
\textbf{Примеры}. Множество положительных действительных чисел с операциями 
умножения (сложения в пространстве) и возведения в действительную степень 
(умножение в пространстве) является векторным пространством; комплексные числа
с операциями сложения и комплексного сопряжения яляются векторным 
пространством; матрицы одного размера образуют линейное пространство; $P^n$ -
\textbf{арифметическое пространство} - строки из $n$ чисел; множество векторов
без одной прямой - не векторное пространство, так как векторы, симметричные 
относительно этой прямой, нельзя сложить.\\
\textbf{Замечание}. Обычно, геометрическими пространствами называются 
пространства размерности 1, 2 или 3.\\
Напомним \textbf{свойства линейных пространств:} единственность нуля и 
противоположного элемента, умножение на скалярный ноль дает вектор-ноль, 
умножение на минус скаляр дает минуc вектор, единственность разности; если 
произведение равно векторному нулю, то либо вектор ноль, либо скаляр ноль.
\subsection{Линейные оболочки и подпространства}
\begin{defin}
Линейная оболочка $L(M)$ множества векторов $M\subset V$ - множество всех 
линейных комбинаций векторов из множества $M$
\end{defin}
\begin{defin}
Подмножество $L$ векторов линейного пространства V называется подпространством,
если выполнены условия:
\end{defin}
$1$. $\forall \Vec{x}, \Vec{y} \in L: \Vec{x}+\Vec{y}\in L$\\
$2$. $\forall \Vec{x} \in L \quad\forall 
\lambda\in \mathbb F: \lambda\Vec{x}\in L $\\
\textbf{Примеры}. Нулевой элемент - нульмерное подпространство; поле над самим 
собой - одномерное подпространство; столбец корней СЛАУ лежит в 
подпространстве, порожденном системой строк СЛАУ; тривиальное пересечение двух
подпространств - нулевой вектор.
\begin{defin}
Пусть L - подпространство V. Множество векторов 
$L'=\{x+y\mid x\in L,~y=const,~y\notin L\}$ называется \textbf{гиперплоскостью}
(линейным многообразием), полученной в результате сдвига подпространства на 
вектор $y$.
\end{defin}
\begin{defin}
Совокупность векторов называется линейно зависимой, если существует равная нулю 
нетривиальная линейная комбинация этих векторов, в противном случае - линейно 
независимы
\end{defin}
\begin{theor}\label{linzav}
1. Линейная зависимость системы векторов эквивалентна тому, что один из
векторов линейно выражается через другие\\
2. Система векторов линейно зависима, если её подсистема линейно зависима\\
3. Если система векторов независима, то любая её подсистема линейно независима
\end{theor}
\textbf{Доказательство}. 1. Пусть $x_n$ выражается линейно как
$x_n=a_1x_1+...+a_{n-1}x_{n-1}$, тогда
$\Vec{0}=a_1x_1+...+a_{n-1}x_{n-1}-x_n$.
Если мы положим $a_i=0,~i\in\{1...n-1\}$, тогда получим нетривиальную
комбинацию, равную нулю. Обратно, пусть
система линейно зависима. Значит, существует некоторая
нетривиальная комбинация, равная нулю. Перенесем в правую часть какой нибудь
вектор с ненулевым коэффициентом, и
сократим на него, получим линейную комбинацию, выражающую этот вектор.\\
2. Пусть подсистема линейно зависима. Значит, неё можно составить нетривиальную
нулевую линейную комбинацию.
Добавляя оставшиеся векторы с коээфициентом 0, также получим нетривиальную 
линейную комбинацию, следовательно, вся система зависима. \\
3. Получается инверсией импликации в п.2. Высказвание пункта 2 имеет вид 
$\exists x P(x)\Rightarrow N(y)$, где P - ``подсистема линейна зависимa'', N -
``система линейно
зависима'', а пункта 3 - $\neg N(y)\Rightarrow\forall x\neg P(x)$. Как мы
видим, это одна и та же (перевернутая) импликация. $\square$\\

\begin{theor}
Если в линейном пространстве V каждый из векторов линейно независимой системы
мощности n является линейной комбинацией векторов линейно независимой системы
мощности m, то $n\leqslant m$
\end{theor}
\textbf{Доказательство.} Пусть $x_i=\sum\limits_{j=1}^{m}a_{ij}y_j$ и пусть
$n>m$. Составим линейную комбинацию векторов $x_1,...,x_n$ с
коэффициентами $\lambda_i$: 
$\sum\limits^n_{i=1}\lambda_ix_i=\sum\limits^n_{i=1}
(\lambda_i\cdot\sum\limits_{j=1}^{m}a_{ij}y_j)$. Рассмотрим 
однородную систему из m линейных уравнений с n неизвестными:
$a_{1i}\lambda_i+...+a_{ni}\lambda_i=0,~i\in\{1...m\}$
Так как $n>m$, то наша однородная система имеет нетривиальное (ненулевое)
решение, т.е. существует такой ненулевой вектор $(\lambda_1,...\lambda_n)$, 
который является решением системы. Но тогда $\sum\limits_{i=1}^{n}
\lambda_ix_i=0$ - нетривиальная  
линейная комбинация, равная нулевому вектору. Отсюда следует, что система
векторов $x_1,...,x_n$ линейно зависимa. Но это противоречит условию теоремы,
поэтому $n\leqslant m$. $\square$\\
\textbf{Следствие.} Любые две экивалентные системы векторов имеют одинаковую
мощность.
\begin{defin}
Две системы векторов экивалентны, если все векторы каждой системы линейно 
выражаются через векторы другой системы
\end{defin}
\begin{defin}
\textbf{Ранг} системы векторов - мощность наибольшей линейно независимой 
подсистемы векторов. Ранг линейного пространства называется размерностью 
пространства.
\end{defin}
Например, пространство $C[a,b]$ непрерывных на отрезке $[a,b]$ функций 
бесконечномерно.


\subsection{Переход между базисами}
\begin{defin}
Базис векторного пространства - линейно независимая система с рангом, равным
размерности пространства.
\end{defin}
Базис $\{e_1,...,e_n\}$ мы будем далее обозначать кратко $\{e\}$ или $\{e_n\}$. 

Выясним, как связаны между собой координаты вектора в разных базисах. Пусть у
нас есть два базиса, $\{e\}$ и $\{e'\}$. Выразим векторы базиса $\{e'\}$ через
векторы базиса $\{e\}$: 
\begin{equation}\begin{cases}e'_1=e_1c_{11}+...+e_nc_{n1}\\
\dots\\e'_n=e_1c_{1n}+...+e_nc_{nn}
\end{cases}\label{sist}\end{equation}

\begin{defin}
Транспонированная матрица С системы \ref{sist} называется матрицей перехода от
базиса $\{e\}$ к базису $\{e'\}$:
\end{defin}
$$C=(c_{ij})=\begin{pmatrix}c_{11}&\dots&c_{1n}\\\vdots&\ddots&\vdots\\c_{n1}
&\dots&c_{nn}\end{pmatrix}$$ 
Систему \ref{sist} можно переписать другим способом. Пусть $e'=(e'_1,...,e'_n)$
и $e=(e_1,...,e_n)$ -  строки из символов, обозначающих базисные векторы. Тогда
система \ref{sist} будет иметь вид
\begin{equation}e'=eC\label{sist2}\end{equation}
\begin{theor}
Матрица перехода связывает координатные выражения вектороа в базисах $\{e\}$ 
и $\{e'\}$ согласно равенству
\end{theor}
$$X=CX'$$
\textbf{Доказательство.} 
Пусть $x$ - произвольный вектор, $X$ и $X'$ - столбцы координат в базисах
$\{e\}$ и $\{e'\}$ соответственно. Тогда $x=eX=e'X'$. Но в силу системы 
\ref{sist2} имеем $x=eX=eCX'$, откуда получаем искомое равенство
$X=CX'$. $\square$ \\
\textbf{Замечание.} В силу линейной независимости векторов базисов, 
$det C\ne 0$\\
\textbf{Следствие.} Матрица обратного преобразования есть обратная матрица.
Действительно, умножая равенство $CX'=X$ на $C^{-1}$, имеем $X'=C^{-1}X$.

\subsection{Изоморфизм линейных пространств}
\begin{defin}
Пространства V и W изоморфны, если существует биекция (взаимно-однозначное 
соответствие) $f\colon V\to W$, которая обладает свойствами линейности.
\end{defin}
1. $f(x+y)=f(x)+f(y)$\\
2. $f(\lambda x)=\lambda f(x)$\\
В частности, вектор-ноль изоморфен вектору-нулю. 
\begin{theor}
Все векторные пространства одной размерности $n$ над одним полем $P$ изоморфны
\end{theor}
\textbf{Доказательство.} Выделим в пространстве базис $\{e_n\}$. Тогда каждый
вектор представляется в виде линейных комбинаций базисных векторов. Множество 
строк коэффициентов этих линейных комбинаций канонически отображается (по 
факту, совпадает) в арифметическое $n$-мерное пространство. Нетрудно проверить,
что это изоморфизм. Таким образом, все пространства изоморфны арифметическому
пространству той же размерности, а значит, все они изоморфны. $\square$\\
\textbf{Замечание}. Изоморфизм определен однозначно, только если пространства
состоят из одного (ноль) или двух векторов (причем размерность пространства равна 1).


\subsection{Пересечение и сумма подпространств}
\begin{defin}\makebox{}\\
Пересечение подпространств $V$ и $W$ - множество векторов $W\cap V$\\
Сумма подпространств $V$ и $W$ - множество векторов
$V+W=\{x+y\mid x\in V,y\in W\}$
\end{defin}
\begin{theor}
$dim(V+W)=dimV+dimW-dim(V\cap W)$
\end{theor}
\textbf{Доказательство.} Пусть $\{e_p\}$ - базис пространства $V\cap W$.
Дополним его какими-то векторами $e_{p+1},..,e_k$ до базиса подпространства
$V$ и, с
другой стороны, векторами $e_{k+1},...,e_{k+l-p}$ - до базиса подпространства
$W$. Докажем, что векторы
$e_{1},...,e_{k+l-p}$ линейно независимы.\\
Предположим, что 
$$\sum\limits_{i=1}^{k+l-p}a_ie_i=0$$
Рассмотрим вектор
$$x=\sum\limits_{i=1}^{k}a_ie_i=-\sum\limits_{i=k+1}^{k+l-p}a_ie_i$$
Из первого представления вектора $x$ следует, что он лежит в $V$, а из второго
– что он лежит в $W$. Таким образом, $x\in V\cap W$ и, значит,
$$x=\sum\limits_{i=1}^{p}b_ie_i=-\sum\limits_{i=k+1}^{k+l-p}a_ie_i$$
Так как векторы $e_1,...,e_p,~e_{k+1},...,e_{k+l-p}$ линейно независимы, то
отсюда следует, что $x=0$ и $a_i =0$ при $i=k+1,..,k+l-p$. Далее,
так как векторы$e_1,.., e_k$ линейно независимы, то из равенства 
$$\sum\limits_{i=1}^{k}a_ie_i=0$$
следует, что $a_i=0$ при $i=1,.., k$.

Значит, векторы $e_1,..,e_{k+l-p}$ образуют базис пространства $V+W$, откуда
$dim(V+W)=k+l-p=dimV+dimW-dim(V\cap W)$

\textbf{Замечание.} В пространстве размерности n встречаются подпространства 
всех промежуточных размерностей. Если $V$ - пространство и $U$ - 
подпространсво, то величина $dimV-dimU$ называется \textbf{коразмерность}
подпространства.

\subsection{Прямая сумма подпространств}
\begin{defin}
Пространство V явлется прямой суммой своих подпространств $L_1$ и $L_2$ 
(обозначается $V=L_1\oplus L_2$), если каждый вектор из V представляется
единственной суммой векторов из $L_1$ и $L_2$
\end{defin}
\begin{theor}
Для того, чтобы сумма подпространств $L_1$ и $L_2$
являлась прямой суммой, необходимо и достаточно, чтобы
пересечение $L_1$ и $L_2$ было нульмерным пространством. Если
$L=L_1\oplus L_2$, то $dimL=dimL_1+dimL_2$
\end{theor}
\textbf{Доказательство.} Необходимость. Пусть $x\in L_1\cap L_2$. Тогда,
поскольку нулевой вектор принадлежит обоим подпространствам, в прямой сумме 
лежат векторы $x+0$ и $0+x$ (где 0 и х берутся в разных подпрострнаствах). 
Поскольку сумма должна быть определена однозначно, то $x+0=0+x$, следовательно,
$x=0$\\
Достаточность. Пусть вектор допускает двойное представление: $x=y_1+y_2$ и
$x=z_1+z_2$. Так как $x-x=0$, то $(y_1-z_1)+(y_2-z_2)=0$, но так как как 
векторы в скобках принадлежат одному подпространству, то разность возможна 
только если $y_1=z_1$, $y_2=z_2$, то есть представление единственно. $\square$

\newpage
\section{Евклидовы и унитарные пространства}
\begin{defin}
Евклидово пространство - линейное пространство,  в котором введена операция
скалярного произведения $(a,b)\mapsto\alpha\in\mathbb R$, удовлетворяющая 
свойствам
\end{defin}
1. $(a,b)=(b,a)$\\
2. $(\lambda a,b)=\lambda(a,b)~\lambda\in\mathbb R$\\
3. $(a+b,c)=(a,c)+(b,c)$\\
4. $(a,b)\geqslant0$\\
5. $(a,a)=0\Leftrightarrow a=0$\\
Вещественное евклидовое пространство обозначается буквой Е
\begin{defin}
Унитарное пространство - линейное пространство, в котором введена операция 
скалярного произведения $(a,b)\mapsto\alpha\in\mathbb C$, удовлетворящая
свойствам
\end{defin}
1. $(a,b)=\overline{(b,a)}$\\
2. $(\lambda a,b)=\lambda(a,b)~\lambda\in\mathbb C$\\
3. $(a+b,c)=(a,c)+(b,c)$\\
4. $0\leqslant(a,a)\in\mathbb R$\\
5. $(a,a)=0\Leftrightarrow a=0$\\
Унитарное пространство обозначается буквой U. В отличие от евклидовых
пространств, скалярное произведение в ортономированном координатном базисе
определяется как $\sum\limits_ix_i\overline{y_i}$ (аналогично для матриц). 
Также заметим, что в силу некоммутативности $(a,\lambda b)=\overline{\lambda}
(a,b)$
\begin{theor}(неравенство Коши-Буняковского)\\
Для любых двух векторов из евклидова (унитарного)
пространства имеем
\end{theor}
$$|(x,y)|^2\leqslant(x,x)(y,y)$$
\textbf{Доказательство.} Для любого коэффициента в силу аксиомы 4 имеем 
$(\lambda x-y,\lambda x-y)\geqslant0$. Тогда $(\lambda x-y,\lambda x-y)=
|\lambda|^2(x,x)-\lambda(x,y)-\overline{\lambda(y,x)}+(y,y)\geqslant0$.
Представим комплексное число $(x,y)$ в тригонометрическом виде: $(x,y)=|(x,y)|
(\cos\varphi+i\sin\varphi)$. Возьмем t -
действительное число такое, что $\lambda=t(\cos\varphi-i\sin\varphi)$. Тогда
$|\lambda|=|t|$,
$\lambda(x,y)=\overline{\lambda(x,y)}=t|(x,y)|$. Поэтому из неравенства выше
следует $t^2(x,x)-2t(x,y)+(y,y)\geqslant0$. Значит, дискриминант этого 
уравнения $\square$

Необходимым и достаточным условием неотрицательности квадратного трехчлена по 
переменной t является
неположительность его дискриминанта, т.е. выполнение неравенства:
$|(x,y)|^2-(x,x)(y,y)\leqslant0$,
что эквивалентно неравенству Коши-Буняковского.
В евклидовом пространстве: $(x,y)^2\leqslant(x,x)(y,y)$.

Неравенство Коши-Буняковского обращается в равенство тогда и только тогда, 
когда векторы x, y коллинеарны:
$(\lambda x-y,\lambda x-y)=0$, если $\lambda x=y$ .

\subsection{Норма вектора}
\begin{defin}
Линейное пространство V называется нормированным, если введена функция нормы
$\|\cdot\|\colon V\to\mathbb R$, которая выполняет роль длины вектора и 
удовлетворяет аксиомам:
\end{defin}
1. $\|x\|\geqslant0~~(\|x\|=0\Leftrightarrow x=\Vec{0})$\\
2. $\|\lambda x\|=|\lambda|\cdot\|x\|$\\
3. $\|x+y\|\leqslant\|x\|+\|y\|$\\
Для евклидовых пространств норму можно определить как $\|x\|=\sqrt{(x,x)}$.
Очевидно, здесь выполняются свойства 1 и 2, неравенство треугольника 
проверяется с помощью неравенства Коши-Буняковского. Действительно, из него
следует, что $|(x,y)|\leqslant\|x\|\cdot\|y\|$. С другой стороны, 
$\|x+y\|=\sqrt{(x,x)+2(x,y)+(y,y)}\leqslant\sqrt{\|x\|^2+2\|x\|\cdot\|y\|+
\|y\|^2}=\|x+y\|$ Как следствие, получаем неравенство $|\|x\|-\|y\||\leqslant
\|x+y\|\leqslant\|x\|+\|y\|$
\begin{defin}
Вектор называется нормированным, если его норма (длина) равна единице.
\end{defin}
Нормировать вектор можно так: $x'=\frac{x}{\|x\|}$

\subsection{Ортонормированная система векторов}
\begin{defin}
Система векторов называется ортогональной, если все её векторы попарно 
ортогональны: $(x_i,x_j)=0,~i\ne j$\\
Система векторов ортонормированная, если выполняется условие
\end{defin}
$$(x_i,x_j)=\delta_{ij}=\begin{cases}1,~i=j\\0,~i\ne j,\end{cases}
$$
\begin{theor}
Ортогональная система векторов линейно независима.
\end{theor}
\textbf{Доказательство.} Рассмотрим линейную комбинацию $a_1x_1+...+a_nx_n=0$.
Умножая скалярно её на $x_k$, получаем $a_k(x_k,x_k)=0$. Значит, $a_k=0$. 
Повторяя это для всех векторов, придем к тому, что линейная комбинация 
тривиальна, то есть векторы линейно независимы. $\square$
\begin{theor}
В ортонормированном базисе $\{e\}$ координаты $(x_1...x_n)$ векторa x
вычисляются как $x_i=(x,e_i)$
\end{theor}
\textbf{Доказательство.} $x=x_1e_1+...x_ne_n$. Беря скалярное произведение на 
$e_k$ слева и справа, получаем $(x,e_k)=x_k(e_k,e_k)=x_k$. $\square$
\begin{theor}
В евклидовом (унитарном) пространстве скалярные произведения в 
ортонормированных базисах вычисляются согласно следующим формулам:
\end{theor}
В евклидовом: $(x,y)=\sum\limits^n_{i=1}x_iy_i$\\
B унитарном: $(x,y)=\sum\limits^n_{i=1}x_i\overline{y_i}$\\
\textbf{Доказательство.} Пусть в ортонормированном базисе $\{e\}$ векторы 
представляются как $x=x_1e_1+...x_ne_n,~y=y_1e_1+...+y_ne_n$. Тогда:
$$(x,y)=(\sum\limits^n_{i=1}x_ie_i,\sum\limits^n_{i=1}y_ie_i)=\sum\limits
^n_{i=1}\sum\limits^n_{k=1}x_i\overline{y_k}(e_i,e_k)=\sum\limits^n_{i=1}x_i
\overline{y_i}\quad\square$$

\subsubsection{Ортогонализация по Граму-Шмидту}
\begin{theor}
В любом n-мерном евклидовом (унитарном) пространстве найдется ортонормированный
базис.
\end{theor}
\textbf{Доказательство.} Опишем процесс ортогонализации произвольного множества
из n векторов по индукции. Возьмем произвольный ненулевой вектор и отнормируем
его: $f'=\frac{f}{\|f\|}$\\
Далее, пусть в $n-1$-мерном подпространстве есть ортонормированный базис 
$\{e_{n-1}\}$, а в самом пространстве - (произвольный) базис $\{f_n\}$. 
Линейная оболочка $L(f_1...f_{n-1})$ будет
подпространством, базисом которого является $\{e_{n-1}\}$. Так как $f_n$ не
принадлежит этому подпространству, вектор $g_n=f_n-a_1e_1-...-a_{n-1}e_{n-1}$
отличен от нулевого вектора.
Выберем координаты $a_i$ так, чтобы $g_n$ был ортогонален всем векторам из 
базиса $\{e_{n-1}\}$. Отсюда получаем формулу $a_i=(f_n,e_i)$, и определим 
новый вектор как $e_n=\frac{g_n}{\|g_n\|}$. $\square$\\
Отсюда можно вывести процесс ортагонализации ситемы векторов $\{f\}$ - 
превращение её в ортонормированный базис $\{e\}$:\\
1. $e_1=\frac{f_1}{\|f_1\|}$\\
2. $e'_k=f_k-\sum\limits^{k-1}_{i=1}(f_k,e_i)e_i,~e_i=\frac{e'_i}{\|e'_i\|}$\\
Через n шагов получим ортонормированный базис.

\subsection{Унитарные и ортогональные матрицы}
\begin{defin}
Эрмитово сопряжение комплексной матрицы - комбинация
транспонирования и комплексного сопряжения матрицы
\end{defin}
$$(a_{ij})^H=(\overline{a_{ji}})$$
\begin{defin}
Комплексная матрица называется унитарной, если $UU^H=U^HU=E$\\
Вещественная матрица называется ортогональной, если 
$Q^TQ=QQ^T=E$\\
Комплексная матрица называется эрмитовой, если $U^H=U$\\
Вещественная матрица назыается симметрической, если $Q^T=Q$
\end{defin}
Если матрица эрмитова, то её определитель вещественен.
\begin{defin}
Матрица Грама системы векторов $a_1,...a_n$ - матрица, определенная как 
\end{defin}
$$\Gamma=\Gamma(a_1,...a_n)=\begin{pmatrix}(a_1,a_1)&\ldots&(a_n,a_1)\\\vdots&
\ddots&\vdots\\(a_1,a_n)&\ldots&(a_n,a_n)\end{pmatrix}$$
Матрица Грама является симметрической (эрмитовой), её определитель еотрицателен.
Система векторов линейно зависима тогда и только тогда, когда определитель её
матрицы Грама равен 0.

Теперь найдем формулу для скалярного произведения векторов в произвольном 
базисе $\{f\}$. Пусть $x=\sum\limits^n_{i=1}x_if_i,~y=\sum\limits^n_{i=1}y_if_i$.
Тогда
$$(x,y)=(\sum\limits^n_{i=1}x_if_i,\sum\limits^n_{j=1}y_jf_j)=\sum\limits^n_
{i=1}\sum\limits^n_{j=1}x_i\overline{y_j}(f_i,f_j)$$
где $(f_i,f_j)$ - элемент матрицы Грама для базиса $\{f\}$.

Если $\{e\}$ - ортонормированный базис, то $\Gamma(\{e\})=E$, a
$\Gamma(a_1,...,a_n)=A^TA$, где А - матрица, составленная из координатных 
векторов-столбцов $a_i$ в базисе $\{e\}$.

Исходя их этого, получаем, что в векторно-матричном виде 
$(x,y)=X^T\Gamma\overline{Y}$, где $X,~Y$ - векторы-столбцы в некотором базисе,
$\Gamma$ - матрица Грама этого базиса.

Если C – матрица перехода от базиса $\{e\}$ к базису
$\{e'\}$, то матрицы Грама этих базисов связаны формулой $\Gamma'=C^T\Gamma 
\overline{C}$.

\subsection{Ортогональное дополнение}
\begin{defin}
Вектор х называется ортогональным к подпространству L, если этот вектор
ортогонален каждому вектору из L; обозначается как $x\perp L$.\\
Ортогональное дополнение к подпространству L - множество 
\end{defin}
$$L^\perp=\{x\mid x\perp L\}$$
\begin{theor}
Ортогональное дополнение - линейное подпространство.
\end{theor}
\textbf{Доказательство.} Пусть $x,y\in L^\perp$ и $z\in L$. Тогда 
$(x,z)=(y,z)=0$ и $(x+y,z)=0$, значит, $x+y\in L^\perp$. Аналогично 
показывается, что $\alpha x\in L^\perp$. $\square$
\begin{theor}
Если L - подпространство V, то $V=L\oplus L^\perp$.
\end{theor}
\textbf{Доказательство.} Пусть $\{e_k\}$ - ортонормированный базис в 
$L$, $\{e_{n-k}\}$ - ортонормированный базис в $L^\perp$. Объединение этих 
базисов $\{e_n\}$ также ортонормированно, и линейно независимо. Покажем, что 
получился базис пространства V. Пусть есть ненулевой вектор, который не 
является комбинацией векторов из базиса. Добавляя его к множеству базисных, 
получаем тем самым независимую систему. С одной стороны, этот вектор 
принадлежит $L^\perp$, поскольку он независим от векторов $\{e_k\}$, с другой 
стороны, он ортогонален $L^\perp$, так как он независим от векторов 
$\{e_{n-k}\}$. Значит, он равен нулю, что противоречит условию. $\square$ \\
\textbf{Следствие.} $dimL+dimL^\perp=dimV$, и для каждого вектора существует
единственная ортогональная проекция на подпространство. 
\begin{defin}
Вектор $g\in L$ называется ортогональной проекцией вектора f на 
подпространство L, если $h\in L^\perp$ и $f=h+g$. Вектор h назывется
ортогональной составляющей вектора f.
\end{defin}
Отметим, что выполняется теорема Пифагора в виде $\|f\|^2=\|h\|^2+\|g\|^2$.

Чтобы найти ортогональную проекцию $g$ вектора $f$ на произвольное 
подпространство $L$, необходимо, чтобы выполнялись условия:
$$\begin{cases}
f=g+h\\g\in L\\h\in L^\perp
\end{cases}\Leftrightarrow\begin{cases}
g=\sum\limits^k_{j=1}x_ja_j\\(\sum\limits^k_{j=1}x_ja_j, a_i)=(f,a_i)~\forall
i\\h=f-g
\end{cases}$$
Значит, задача сводится к поиску решения $(\sum\limits^k_{j=1}x_ja_j, a_i)=
(f,a_i)$, в матрично-векторном виде $g\Gamma=f$.

Естественным образом определяется ортогональное отражение $f-2h$ вектора $f$
относительно подпространства $L$.
\begin{theor}
Длина между вектором $f$ и подпространством $L$ есть длина перпендикуляра,
опущенного из $f$ на $L$.
\end{theor}
\textbf{Доказательство.} Пусть $f=g+h$, где
$g\in L$, $h\in L^\perp$. Пусть $y\in L$ – произвольный
вектор. Обозначим через $\rho( f , y)$ расстояние
между векторами $f$ и $y$. Тогда $\rho(f,y)=|f-y|=|(g+h)-y|=|g+(h-y)|$, откуда
следует, что минимум расстония достигается при $y=h$, то есть при перпендикуляре. $\square$

Точно так же по принципу минимума вводится понятие угла между вектором и
подпространством (как минимум углов между вектором и вектором из
подпространства).
\begin{defin}
Пусть $\{f_k\}$ - линейно независимая система векторов. k-мерным 
параллелепипедом, построенным на этой системе, называется множество линейных
комбинаций векторов этой системы с коэффициентами $a_i\in[0,1]$\\
Объем $V\{f_k\} $k-мерного параллелипепеда (рекурсивно) определяется как
произведение высоты на объем k-1-мерного основания и корня из определителя 
матрицы Грама системы $\{f_k\}$.
\end{defin}
Если $\{e_k\}$ - базис, и $F$ - матрица, составленная из координатных столбцов
системы $\{f_k\}$ в базисе $\{e_k\}$, то $V\{f_k\}=|detF|\sqrt{det\Gamma_e}=
|detF|V\{e_k\}$. Если базис ортонормированный, то $V\{f_k\}=|detF|$.


\subsection{Дополнение. Формулы проекций}
Пусть $a$ - направляющий вектор одномерного подпространства $A$, $n$ - вектор 
нормали к подпространству $L$.
\begin{itemize}
\item Ортогональное проектирование вектора $x$ на $A$ дается формулой
$$x_{pr}=\frac{(x,a)}{|a|^2}a$$
\item Ортогональное проектирование на $A$ параллельно $L$ дается формулой
$$x_{pr}=\frac{(x,n)}{(a,n)}a$$

\end{itemize}





\newpage
\section{Линейные операторы}
\begin{defin}
Пусть V,W - линейные пространства над полем Р. \textbf{Линейным оператором}
$\mathcal A\colon V\to W$ называется функция, для всех векторов $x,y\in V$ и 
чисел $\alpha\in P$ удовлетворяющая условиям:
\end{defin}
1. $\mathcal A(x+y)=\mathcal Ax+\mathcal Ay$\\
2. $\mathcal A(\alpha x)=\alpha\mathcal Ax$

Множество всех линейных операторов из $V$ в $W$ мы обозначаем $L(V,W)$. Если
оператор $\mathcal A\in L(V,V)$, то мы будем иногда называть его 
\textit{линейным автоморфизмом} пространства V, подчеркивая, что оператор 
осуществляет преобразование пространства в себя. Если $\mathcal A\in L(V,W)$,
где $W=P$ - пространство, равное полю, то такой оператор называют 
\textit{линейным функционалом}.

Естественным образом можно определить равенство операторов, нулевой оператор
(который все векторы отображает в вектор-ноль), обратный оператор. Также
можно ввести сложение операторов и умножение на скаляр. Эти операции задают
структуру линейного пространства в $L(V,W)$. Можно показать, что в случае 
конечных размерностей $V$ и $W$, $L(V,W)$ изоморфно пространству матриц 
соответствующего размера. 

\textbf{Свойства линейных операторов}\\
1. $\mathcal A0=0$\\
2. $\mathcal A(\sum\limits_i\alpha_ix_i)=\sum\limits_i\alpha_i\mathcal Ax_i$\\
3. Линейный оператор сохраняет линейную заисимость.\\
Из свойства 2 следует, что для задания линейного оператора достаточно задать
его действие на базисные векторы. 


\subsection{Матрица линейного оператора}
Пусть $\mathcal A\in L(V,W)$, $\{e_n\}$ и $\{f_m\}$ - базисы соответственно
в $V$ и $W$. Действие оператора однозначно задается его действием на
базисные векторы $\mathcal Ae_1...\mathcal Ae_n$, которые в свою очередь 
выражаются в базисе $\{f\}$:
$$\mathcal Ae_i=a_{1i}f_i+...+a_{mi}f_m$$
Это позволяет нам определить матрицу $A_{fe}$ размера $m\times n$, которая
называется матрицей оператора в базисах $\{e_n\}$ и $\{f_m\}$.
\begin{theor}
Если $y=\mathcal Ax$, то $y_f=A_{fe}x_e$.
\end{theor}
\textbf{Доказательство.} Пусть $$x=\sum\limits_{i=1}^nx_ie_i~~y=\sum\limits_
{i=1}^my_ie_i$$
Имеем $$\mathcal Ax=y=\mathcal A(\sum\limits_{j=1}^nx_je_j)=\sum\limits_{j=1}
^nx_j\mathcal Ae_j=\sum\limits_{j=1}^nx_j\sum\limits_{i=1}^ma_{ij}f_i $$
то есть $y_i=\sum\limits_{j=1}^na_{ij}x_j$. $\square$

\begin{theor}\label{basis_operators}
Пусть $\{e\}$, $\{t\}$ - различные базисы в $V$, $\{f\}$ и $\{s\}$ - базисы
в $W$. Тогда имеет место соотношение $$A_{st}=D^{-1}A_{fe}C,$$ где $t=eC$,
$s=fD$.
\end{theor}
\textbf{Доказательство.} Пусть $Y_f=A_{fe}X_e$, $Y_s=A_{st}X_t$. По условию,
$x=eX_e=tX_t=eCX_t$,  $y=fY_f=sY_s=fDY_s$, откуда $X_e=CX_t,~Y_f=DY_s$. 
Отсюда получаем $A_{fe}CX_t=DY_s$, значит, $D^{-1}A_{fe}C=A_{st}$. $\square$

\textbf{Свойства матриц линейных операторов}\\
1. Матрицы линейного оператора в различных парах базисов эквивалентны.\\
2. Ранг матрицы линейного оператора не зависит от выбора пар базисов.\\
3. Линейное пространство $L(V,W)$ изоморфно пространству матриц 
$P^{m\times n}$, и $dimL(V,W)= dimV\cdot dimW=nm$.\\
4. Сумма матриц соответствует сумме операторов.

\subsection{Произведение линейных операторов}
\begin{defin}
Пусть V,W,Z – линейные пространства над полем
P. Композицией (или произведением) операторов $\mathcal A\in L(V,W)$ и
$\mathcal B\in L(W,Z)$ называется оператор $\mathcal C\in L(V,Z)$, который
действует по правилу
\end{defin}
$$\mathcal Cx=\mathcal B(\mathcal Ax)$$
Очевидно, что композиция линейных операторов линейна.

\textbf{Cвойства композиции операторов}\\
1. Ассоциативность\\
2. $\alpha(\mathcal A\mathcal B)=(\alpha\mathcal A)\mathcal B=\mathcal
(\alpha A\mathcal B)$\\
3. Левая и правая дистрибутивность относительно сложения\\
4. Коммутативность работает только для линейных \textit{авто}морфизмов.
\begin{theor}
При композиции матрицы операторов перемножаются.
\end{theor}
\textbf{Доказательство}. Рассмотрим вектор как линейную комбинацию базисных 
векторов и подействуем последовательно на них операторами. $\square$\\

\subsection{Образ и ядро}
\begin{defin}\makebox{}\\
\textbf{Образ оператора} $im\mathcal A$ - множество всех векторов, которые
могут быть получены действием оператора\\
\textbf{Ядро оператора} $ker\mathcal A$ - множество векторов, переходящих под 
действием оператора в вектор-ноль
\end{defin}
Ядро оператора непусто (так как по крайней мере вектор-ноль переходит в 
вектор-ноль). Если ядро оператора состоит только из вектора-нуля, то оператор
задает биекцию. 

Если $\mathcal A\in L(V,W)$, то $kerA$ линейное подпространство пространства
$V$, а $imA$ – линейное подпространство пространства $W$.

\begin{defin}\makebox{}\\
\textbf{Ранг линейного оператора} $rk \mathcal A$ - размерность образа 
линейного оператора.\\
\textbf{Дефект линейного оператора} $def\mathcal A$ - размерность ядра 
линейного оператора.
\end{defin}
Размерность пространства - области определения оператора - равна сумме 
дефекта и ранга оператора. Образ пространства - линейная оболочка образа базиса. 
\begin{theor}
Ранг линейного оператора равен рангу его матрицы в произвольной паре базисов.
\end{theor}
\textbf{Доказательство.} Действительно, $rk\mathcal A=dim(im\mathcal A)=
dimL(\mathcal Ae_1...\mathcal Ae_n)=rk(\mathcal Ae_1...\mathcal Ae_n)$. 
Ранг этой
системы векторов совпадает с рангом системы арифметических векторов, 
составленной из координат
этих векторов в базисе $f$ пространства $W$, т.е. с рангом матрицы $A_{fe}$.
$\square$
\begin{theor} (о каноническом виде матрицы оператора).
Пусть $\mathcal A\in L(V_n,W_m)$, $rk\mathcal A=r$. Тогда существуют базисы
$\{e\}$ и $\{f\}$ пространств V и W, в которых оператор $\mathcal A$
вида $$I_r=\begin{pmatrix}\boxed{E}&0\\0&0\end{pmatrix}$$
где $E$ - единичная матрица размера $r\times r$. Базисы $\{e\}$ и $\{f\}$ 
называются канонической парой базисов.
\end{theor}
\textbf{Доказательство.} Если $r=0$, то матрица $I_r$ состоит из нулей, и в
любом базисе она является матрицей нулевого оператора. Пусть $r>0$, тогда по
теореме о методе Гаусса-Жордана подматрицу размера $r\times r$ в матрице $A$ 
можно привести к единичному виду. Поскольку все остальные строки/столбцы 
линейно зависимы, они будут нулевыми. Итак, $I_r=AC$, где $C$ - произведение 
матриц элементарных преобразований. Оно не вырождено, поскольку элементарные
преобразования не вырождены. Значит, мы можем представить матрицу канонического
вида как $I_r=E^{-1}AC$, что по теореме \ref{basis_operators} дает нам 
существование канонических базисов. $\square$


\subsection{Алгебра линейных операторов}
Пусть $V$ - линейное пространство над полем $P$. Мы знаем, что $L(V,V)$ -
векторное пространство относительно операций сложения операторов и умножения
оператора на скаляр. Кроме того, относительно операций сложения и композиции 
векторов $L(V,V)$ яляется коммутативным кольцом с единицей. Значит, $L(V,V)$ 
является алгеброй. 
\begin{defin}
Алгебра над полем - множество с введенными операциями сложения, умножения и
умножения на скаляр такое, что относительно первой и третьей оно явлеятся 
векторным пространством, а относительно первой и второй - кольцом. Кроме того,
выполняется дополнительное условие (для связи всех операций):
\end{defin}
$$\mathcal A(\alpha\mathcal B)=(\alpha\mathcal A)\mathcal B=\alpha
(\mathcal A\mathcal B)$$
\textbf{Свойства алгебры операторов}\\
1. Можно ввести возведение оператора в степень и определить многочлены от 
операторов.\\
2. В разных базисах одному оператору могут соответствовать разные матрицы. 
Таким образом, одному и тому же оператору соответствует целый класс 
эквивалентных матриц, которые называются \textbf{подобными}. Если $\{e\}$ и
$\{f\}$ - базисы пространства, и $f=eC$ - матрица перехода, то $A_f=C^{-1}A_eC$.
В частности, матрица нулевого оператора в любом базисе - нулевая матрица,
матрица тождественного опеатора - всегда единичная матрица.\\
3. Ранг оператора равен рангу матрицы.\\
4. Определители всех матриц одного оператора равны. Действительно,
$detA_f=det(C^{-1}A_eC)=detA_e\cdot det(C^{-1}C)=detA_e$.


\subsection{Обратный оператор}
\begin{defin}
Пусть $\mathcal A\in L(V,V)$ - линейный оператор. Обратным к нему называется
такой оператор $\mathcal A^{-1}$, что
\end{defin}
$$\mathcal A^{-1}\mathcal A=\mathcal A\mathcal A^{-1}=I$$
\textbf{Свойства обратного оператора}\\
1. Обратный оператор существует, если сам оператор является биекцией (то есть
$ker\mathcal A=\{0\},~im\mathcal A=V$)\\
2. Обратный оператор линеен. Доказательство следует из линейности самого 
оператора.\\
3. В произвольном операторе матрица обратного оператора является обратной 
матрицей оператора.\\
4. Обратный оператор единственен.
\begin{defin}
Линейный автоморфизм называется невырожденным, если его ядро состоит из 
одного вектора-нуля.
\end{defin}
\begin{theor}
Следующие утверждения эквивалентны:\\
1. $\mathcal A$ обратим\\
2. $\mathcal A$ невырожден\\
3. $im\mathcal A=V$\\
4. $det\mathcal A\ne0$\\
5. $\mathcal A$ биективен
\end{theor}
\textbf{Доказательство} Демин не дал. Поищем в Винберге xD)) $\square$
\begin{theor}
Композиция обратимых операторов обратима, причем
\end{theor}
$$(\mathcal A\mathcal B)^{-1}=\mathcal B^{-1}\mathcal A^{-1}$$
\textbf{Доказательство.} Произведение невырождено в силу того, что композиция
биекций - биекция. Умножая композицию на обратный к ней оператор, получем 
$\mathcal A\mathcal B\mathcal B^{-1}\mathcal A^{-1}=\mathcal A\mathcal 
A^{-1}=I$, что и требовалось. $\square$


\subsection{Инвариантное подпространство}
\begin{defin}
Пусть $\mathcal A$ - линейный автоморфизм линейного пространства $V$ над
$\mathbb R$ или $\mathbb C$. Подмножество $L\subset V$ называется инвариантным
относительно оператора $\mathcal A$, если
$\forall x\in L\colon\mathcal Ax\in L$
\end{defin}
В частности, вектор-ноль и само пространство инвариантны относительно любого
оператора. Также инвариантными являются образи и ядро линейного оператора. 
\begin{theor}
Пусть $\mathcal A$ - линейный автоморфизм пространства $V$, и $L$ - 
инвариантное подпространство. Тогда существует базис $\{e_n\}$, в котором
матрица оператора имеет квази-треугольную форму. 
\end{theor}
\textbf{Доказательство}. Пусть $\{e_k\}$ - базис в $L$. Дополним его до
$\{e_n\}$. Из инвариантности подпространства следует, что векторы
$\{\mathcal Ae_k\}$ линейно выражаются через $\{e_k\}$. Значит, для базисных 
векторов из L, $\mathcal Ae_i=a_{1i}e_1+...a_{ki}e_k$, для базисных векторов 
из $V\setminus L$ --- $\mathcal Ae_j=a_{1j}e_1+...a_{nj}e_n$. Значит, матрица 
оператора имеет вид
$$A_e=\begin{pmatrix}a_{11}&\ldots&a_{1k}&a_{1k+1}&\ldots&a{1n}\\\vdots&\ddots&
\vdots&\vdots&\ddots&\vdots\\a_{k1}&\ldots&a_{kk}&a_{kk+1}&\ldots&a_{kn}
	\\&&&a_{k+1k+1}&\ldots&a_{k+1n}\\&0&&\vdots&\ddots&\vdots\\&&&a_{nk+1}&
\ldots&a_{nn}\end{pmatrix}$$
--- квази-треугольная форма. $\square$
\begin{theor}
Если $V=L_1\oplus...\oplus L_k$ – прямая сумма подпространств, инвариантных
относительно оператора
$\mathcal A\in L(V,V)$, то в пространстве $V$
существует базис, в котором матрица $A_e$
оператора $\mathcal A$ имеет квазидиагональную форму:
\end{theor}
$$A_e=\begin{pmatrix}\boxed{A_1}&&0\\&\ddots&\\0&&\boxed{A_k}\end{pmatrix}$$
где $\boxed{A_i}$ - матрица размерности подпространства $L_i$\\
\textbf{Доказательство} проводится аналогично доказательству предыдущей 
теоремы. $\square$


\subsection{Индуцированный оператор}
Рассматривая линейный оператор только на его инвариантном подпространстве, 
можно получить новый
оператор. 
\begin{defin}
Пусть L – инвариантное подпространство относительно оператора 
$\mathcal A\in L(V,V)$. Отображение $A|L\colon L\to L$, определенное
равенством: $(\mathcal A|L)x = \mathcal Ax,~\forall x\in L$, называется
индуцированным оператором, порожденным оператором $\mathcal A$.
\end{defin}
Индуцированный оператор линеен, он совпадает с $\mathcal A$ на подпространстве
L и не определен вне его: $(A|L)\in L(L, L)$.


\subsection{Собственные значения и собственные векторы}
\begin{defin}
Ненулевой вектор х называется \textbf{собственным вектором} оператора 
$\mathcal A$, если найдется такое число $\lambda$, что $\mathcal Ax=\lambda x$.
Число
$\lambda$ называется \textbf{собственным значением} оператора $\mathcal A$,
соответствующее собственному вектору х. Множество собственных значений 
оператора $\mathcal A$ называется его \textbf{спектром}.
\end{defin}
Аналогичным образом определяются собственные векторы-столбцы для матриц. 
Геометрически, собственные векторы - это векторы, при действии на которых 
оператором или матрицей они не меняют направления, изменяется только их длина. 
Поскольку матрицы соответствуют операторам, то действие последних может 
быть записано в матричном виде через базисы.
\begin{theor}
Собственные векторы оператора, отвечающие различным собственным значениям,
линейно независимы.
\end{theor}
\textbf{Доказательство.}  Пусть $x_1$ и $x_2$ – собственные векторы, отвечающие
собственным значениям 
$\lambda_1$ и $\lambda_2$. Докажем, что равенство 
$\alpha_1x_1+\alpha_2x_2=0$ возможно тогда и только тогда, когда $\alpha_1=
\alpha_2=0$.
Имеем: $\mathcal A(\alpha_1x_1+\alpha_2x_2)=\alpha_1\lambda_1x_1+\alpha_2
\lambda_2x_2=0$.
Отнимая из этого соотношение уравнение $\lambda_2\alpha_1x_1+\lambda_2
\alpha_2x_2$, получаем $\alpha_1(\lambda_1-\lambda_2)x_1=0$.
Так как $\lambda_1\ne\lambda_2$, то это равенство возможно, если $\alpha_1=0$.
Аналогично, можно доказать, что $\alpha_2=0$,
что и доказывает теорему. $\square$\\
\textbf{Следствие.} Линейный оператор, действующий в n-мерном пространстве, 
имеет не более n собственных векторов.


\subsection{Характеристический многочлен}
Матричное равенство $Ax=\lambda x$ можно переписать в виде $(A -\lambda E)x=0$.
Это служит мотивировкой, чтобы ввести 
\begin{defin}
Характеристичсекий многочлен - многочлен, определенный как 
\end{defin}
$$\triangle(\lambda)=det(A-\lambda E)=(-\lambda)^n+a_{n-1}(-\lambda)^{n-1}+
...+a_1(-\lambda)+a_0$$
где $a_{n-1}=trA,~a_0=detA$\\ 
($trA$ - след матрицы $A$ - сумма её диагональных элементов)\\
Над полем $\mathbb C$ характеристический многочлен имеет столько корней,
какова его степень. Над другими полями корней может и не быть. Из этого 
следует, что в униатрном пространстве у любого многочлена имеется хотя б один 
собственный вектор (по основной теореме алгебры), и на любом инвариантном 
подпространстве имеется хотя бы один собственный вектор.
\begin{theor}\label{harakt_mnch_podob}
Характеристические многочлены подобных матриц равны.
\end{theor}
\textbf{Доказательство.} Пусть $A'=C^{-1}AC$, где $C$ - невырожденная матрица. 
Тогда $|A'-\lambda E|=|C^{-1}AC-\lambda E|=|C^{-1}(AC-\lambda CE)|=|C^{-1}
(A-\lambda CEC^{-1})C|=|C{^-1}|\cdot|A-\lambda E|\cdot|C|=|A-\lambda E|$.
$\square$
\begin{theor}
Множество корней характеристического многочлена совпадает со спектром оператора.
\end{theor}
\textbf{Доказательство.} Пусть $\lambda_0$ - собственное значение матрицы $A$. 
Тогда найдется такой ненулевой вектор $x$, что $Ax=\lambda_0x$, что эквивалентно
$(A -\lambda_0 E)x=0$. Допустим, у матрицы $(A -\lambda_0 E)$ есть обратная; 
тогда, домножая равенство на эту марицу слева, получим $x=0$, что противоречит
нашему предположению. Значит, у матрицы $(A -\lambda_0 E)$ нет обратной, и 
тогда $|A -\lambda_0 E|=0$, но это означает, что $\lambda_0$ - корень 
характеристического многочлена. 
Обратно, пусть $\lambda_0$ - корень характеристического многочлена. Тогда $|A
-\lambda_0 E|=0$, и значит найдутся ненулевые векторы такие, что $(A -
\lambda_0 E)x=0$. Их этого следует $Ax=\lambda_0x$, откуда $\lambda_0$ -
собственное значение. $\square$


\begin{defin}
\textbf{Алгебраическая кратность} собственного значения $m_i$ - кратность корня
$\lambda_i$ в характеристическом многочлене.
\end{defin}
Если $\lambda_i$ – собственное значение оператора $\mathcal A$, то множество 
$W_{\lambda_i}=\{x\mid\mathcal Ax=\lambda_ix\}$ называется \textbf{собственным
подпространством} оператора $\mathcal A$, отвечающим собственному значению 
$\lambda_i$.
Очевидно, что $W_{\lambda_i}=ker(\mathcal A-\lambda_iI)$ поэтому собственное
подпространство является линейным подпространством пространства $V$. 
$W_{\lambda_i}$ состоит из нулевого вектора и всех собственных векторов, 
отвечающих собственному значению $\lambda_i$.
Собственное подпространство $W_{\lambda_i}$
инвариантно относительно оператора A.
\begin{defin}
Размерность собственного подпространства $W_{\lambda_i}$
называется геометрической кратностью собственного значения $\lambda_i$ и
обозначается $s_i$
\end{defin}
Очевидно, $s_i=n-rk(A_e-\lambda_iE)$, где $n$ - порядок матрицы $A_e$, или же 
размерность пространства. 
\begin{theor}
Геометрическая кратность собственного значения не превосходит его 
алгебраической кратности.
\end{theor}
\textbf{Доказательство.} Пусть $\lambda_i$ - собственное значение 
алгебраической кратности $m_i$, тогда характеричтический многочлен можно
представить в виде $\triangle(\lambda)=(\lambda-\lambda_i)^{m_i}g(\lambda)$.
Согласно уравнению $\mathcal Ax=\lambda_ix$, матрица оператора в базисе из 
собственных векторов будет иметь диагональный вид с элементами $\lambda_i$ на 
главной диагонали. $\square$
\begin{theor}
Сумма собственных подпространств оператора, отвечающих различным собственным
значениям, является прямой суммой.
\end{theor}
