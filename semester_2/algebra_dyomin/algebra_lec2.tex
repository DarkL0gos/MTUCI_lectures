\subsection{Линейные операторы простой структуры}
\begin{defin}
Линейный оператор $\mathcal A\in L(V,V)$ называется оператором простой 
струтуры, если его собственные векторы образуют базис в $V$.
\end{defin}
\begin{theor}\label{diagonal_matrix}
Оператор $\mathcal A$ наделен простой структурой тогда и только тогда, когда 
существует базис, в котором его матрица диагональна, причем на диагонали стоят
его собственные числа. 
\end{theor}
\textbf{Доказательство.} Пусть $e_i$ - собственный вектор оператора $\mathcal A$
с собственным значением $\lambda_i$. Тогда $\mathcal Ae_i=\lambda_ie_i$. $\square$\\
\textbf{Следствие.} В линейном пространстве $P^n$ линейный оператор с $n$ 
различными собственными числами будет наделен простой структурой. Обратное 
неверно, пример - единичная матрица (тождественный оператор).
\begin{theor}
Оператор $\mathcal A\in L(V,V)$ наделен простой структурой тогда и только 
тогда, когда прямая сумма его собственных подпространств совпадает с $V$: 
$W_{\lambda_1}\oplus...\oplus W_{\lambda_p}=V$, где $p\leqslant n$ - число 
различных собственных значений.
\end{theor}
\begin{theor}
Оператор $\mathcal A\in L(V,V)$, где $V$ - произвольное подпространство, 
наделен простой структурой, если алгебраическая кратность любого собственного 
значения совпадает с геометрической кратностью. 
\end{theor}
Рассмотрим характеристический многочлен $\mathcal A$:
$\triangle(\lambda)=(-1)^n(\lambda-\lambda_1)...(\lambda-\lambda_p)^{m_p}$,
где $m_i=s_i$, то есть алгебраическая кратность равна геометрической кратности
и все это равно $dim(W_{\lambda_i})$\\
$\sum\limits_k m_k=n,~\lambda_i\in\mathbb R$
\begin{defin}
Квадратная матрица А наделена простой структурой, если она подобна диагональной.
\end{defin}
Пусть в базисе $\{f\}$ матрица А имеет вид $A_f$. Мы хотим по возможности 
найти базис, в котором матрица будет иметь диагональный вид. Возьмем базис 
$\{e\}$, где $e_i$ - собственный вектор оператора, соответствующего матрице А.
Тогда $\Delta=C^{-1}AC$, где C - матрица перехода, $\Delta=\begin{pmatrix}
\lambda_1&&\large{0}\\&\ddots&\\\large{0}&&\lambda_n\end{pmatrix}$ - искомая
диагональная матрица.\\
В $\mathbb R^n$ существуют операторы, не имеющие собственных векторов, а в 
$\mathbb C^n$ не всякий оператор обладает необходимым числом линейно 
независимых векторов для того, чтобы иметь простую структуру. 


\subsection{Жорданова клетка матрицы}
\begin{defin}
Жорданова клетка $J_k(\lambda_0)$ порядка k - матрица, которая имеет вид 
\end{defin}
$$J_k(\lambda_0)=\begin{pmatrix}\lambda_0&1&&\large{0}\\&\ddots&\ddots&1\\
\large{0}&&\ddots&\lambda_0\end{pmatrix}$$
В частности, $J_2(\lambda_0)=\begin{pmatrix}\lambda_0&1\\0&\lambda_0
		\end{pmatrix}$, $J_3(\lambda_0)=\begin{pmatrix}\lambda_0&1&0\\0&
\lambda_0&1\\0&0&\lambda_0\end{pmatrix}$\\
У жордановой клетки матрицы характеристический многочлен равен $$\triangle
(\lambda)=(\lambda_0-\lambda)^k=det(J_k(\lambda_0-\lambda E))$$
При этом у $J_k(\lambda_0)$ одно собственное значение алгебраической кратности
$k$.\\
Рассмотрим матрицу $B=J_k(\lambda_0)-\lambda_0E,~~rk(B)=k-1$. Геометрическая 
кратность $s=k-(k-1)=1$, следовательно, это оператор имеет ровно один 
собственный вектор и не имеет простой структуры.


\subsection{Треугольная форма линейного оператора}
\begin{theor}\label{sistinvpod}
Для любого линейного оператора $\mathcal A$ в комплексном пространстве 
размерности n найдется система из n вложенных инвариантных подпространств всех
размерностей: $L_1\subset L_2...\subset L_n=\mathbb C^n$
\end{theor}
\textbf{Доказательство} - по индукции. При $n=1$ теорема очевидна. При $n>1$ 
допустим, что для $n-1$ теорема верна. Нам потребуется следующая\\
\textbf{Лемма}. \textit{Линейный оператор $\mathcal A$ в комплексном 
пространстве размерности n обладает инвариантным подпространством размерности
n-1.}\\
\textbf{Доказательство} Пусть $\lambda$ - собственное число  оператора 
(найдется хотя бы одно, поскольку мы в комплексном пространстве). Тогда 
$det(A-\lambda E)=0$ и $rk(A-\lambda E)\leqslant n-1$, то есть существует
подпространство $W$ со свойствами, которые делают его инвариантным: 
$dim(W)=n-1,~~im(A-\lambda E)\subset W$. $\square$ 

Вернемся к доказательству теоремы. $\mathcal A$, действующий в $\mathbb C^n$,
имеет инвариантное подпространство размерности $n-1$: $L_{n-1}\subset 
\mathbb C^n$. Тогда существует индуцировнный оператор $\mathcal A|L_{n-1}$,
который действует в этом подпространстве, и для него существует система 
вложенных подпространств $L_1\subset L_2...\subset L_{n-1}$. $\square$
\begin{theor}
Для любого линейного оператора найдется базис, в котором его матрица имеет 
треугольную форму.
\end{theor}
\textbf{Доказательство.} Согласно теореме \ref{sistinvpod}, оператор имеет 
систему вложенных инвариантных подпространств $L_1\subset L_2...\subset L_n=V$.
Искомый базис строим следующим образом: $e_1\in L_1,~e_2\in L_2\setminus
L_1~,...,~e_k\in L_k\setminus L_{k-1}$. $\square$\\
\textbf{Замечание 1.} При правильно выбранной нумерации базиса можно получить
верхнюю/нижнюю треугольную матрицу\\
\textbf{Замечание 2.} На главной диагонали стоят собственные числа оператора.

\subsection{Прямая сумма операторов}
\begin{defin}
Если $V=L_1\oplus...\oplus V_p$, где $L_i$ инвариантно относительно линейного
автоморфизма $\mathcal A$, то $\mathcal A$ - прямая сумма индуцированных
операторов $\mathcal A|L_1...\mathcal A|L_p$
\end{defin}
Для всякого вектора $x=\sum\limits_{i=1}^ne_ix_i$, который представим в виде
линейной комбинации векторов из инвариантных подпространств, имеет место 
$$\mathcal Ax=\mathcal A\sum\limits_{i=1}^ne_i x_i=\sum\limits_{i=1}^n\mathcal
A|L_ie_i\cdot x_i$$

\subsection{Нильпотентный оператор}
\begin{defin}
Линенйный оператор называется нильпотентным, если при возведении его в 
некоторую степень получается 0. Наименьшая такая степень Q называется индексом
оператора.
\end{defin}
В частности, $Q=1\Leftrightarrow\mathcal A=0$\\
\textbf{Примеры.} Оператор дифференцирования в пространстве многочленов -
нильпотентный, индекс на единицу больше степени многочлена; жорданова клетка
$J_k(0)=J_k(\lambda_0)-\lambda_0E$ - нильпотентная матрица.
\begin{theor}
 Если для линейного нильпотентного оператора степени Q и вектора $x_0$ имеет 
 место $\mathcal A^{Q-1}x_0\ne0$, то $x_0,~\mathcal A^1x_0,...,\mathcal 
 A^{Q-1}x_0$ - линейно независимы.
\end{theor}
\textbf{Доказательство}.  $\square$

\begin{defin}
Линейное пространство $L(x,\mathcal Ax,...,\mathcal A^{Q-1}x)$ называется 
циклическим подпространством нильпотентного оператора $\mathcal A$, порожденным
вектором $x$.
\end{defin}

\begin{theor}
В комплексном пространстве линейный оператор нильпотентен тогда и только
тогда, когда все его собственные значения равны 0.
\end{theor}
\textbf{Доказательство.} Покажем необходимость. Пусть $\mathcal Ax=\lambda x$.
Тогда и $\mathcal A^q=\lambda^qx$. Тогда, поскольку оператор нильпотентен, для
какого-то $k$ будет иметь место
$\lambda^kx=0$, и поскольку $x\ne0$, $\lambda=0$.\\ Покажем достаточность.
Пусть все собственные значения равны нулю. По теореме о диагонализации, у 
матрицы этого оператора будут находиться нули на
главной диагонали, и какие-то числа сверху от неё. Возводя эту матрицу в 
степень, нули будут подниматься, то есть оператор нильпотентен, его индекс 
равен порядку матрицы. $\square$
\begin{theor}
Произвольный линейный оператор является суммой нильпотентного и обратимого 
оператора
\end{theor}
\textbf{Доказательство.} Рассмотрим характеристический многочлен
$\triangle(\lambda)=(-1)^{n}(\lambda-\lambda_1)^{m_1}...(\lambda-\lambda_p)
^{m_p}$. Пусть $\lambda_1=0$. Тогда оператор, индуцированный на инвариантном 
подпространстве $N_q$, будет нильпотентным. Размерность подпространства
$dimN_q=m_1$, размерн $dimT_q=m_2+...m_p$. $N_q=ker\mathcal A^q$, 
$T_q=im\mathcal A^q$, $V=N_q\oplus T_q$. $\square$\\
Из этой теоремы следует, что мы можем представить характеристический многочлен
в виде $\triangle(\lambda)=(\lambda_1-\lambda)^{m_1}(\lambda_2-\lambda)^
{m_2}...(\lambda_p-\lambda)^{m_p}$, или, как говорят, расщепить его. Такое
расщепление направлено на выделение в $V$ максимального подпространства $V_q$,
на котором индуцированный оператор нильпотентен.



\subsection{Корневые подпространства}
\begin{theor}\label{raschep}(о расщеплении оператора)\\
Для любого оператора с характеристическим многочленом $\triangle(\lambda)=
(\lambda_1-\lambda)^{m_1}...(\lambda_p-\lambda)^{m_p},~\lambda_i\ne\lambda_j$
в комплексном n-мерном пространстве существуют инвариантные подпространствa,
называемые \textbf{корневыми}, такие что $\mathbb C^n=K_{\lambda_1}\oplus
...\oplus K_{\lambda_p}$ и $dim(K_{\lambda_i})=m_i$.
\end{theor}
\textbf{Доказательство.} $f_\lambda=f_1(\lambda)...f_p(\lambda)$, где $f_i
(\lambda)=(\lambda_i-\lambda)^{m_i}=det(\mathcal A|K_{\lambda_i}-\lambda E)$, 
то есть $\forall x\in K_{\lambda_i},~\mathcal A|K_{\lambda_i}x=\mathcal Ax$.
Это и означает, что оператор является прямой суммой индуцированных операторов
на инвариантных подпространствах. $\square$\\
Теперь покажем, какие именно это подпространства. Поскольку $A|K_{\lambda_i}x
=\mathcal Ax$, то $K_{\lambda_i}$ состоит из всех векторов $x$ таких, что
$(\mathcal A-\lambda_iI)^kx=0,~k\geqslant 0$. Другая формулировка:
$K_{\lambda_i}$ является ядром оператора $N_q=(\mathcal A-\lambda_iI)^q$, 
причем $N_{q+1},~N_{q+2}...$ совпадают с $N_q$. 
\begin{defin}
x - корневой вектор для оператора $\mathcal A$ и собственного значения
$\lambda_i$, найдется такое число k, что $(\mathcal A-\lambda_i I)^kx=0$.
\end{defin}
При $k=1$ - собственный вектор для оператора \\
При $k>1$ - собственный вектор для $(\mathcal A-\lambda_iI)^k$, тогда 
$(\mathcal A-\lambda_iI)^1,...,(\mathcal A-\lambda_iI)^k$ линейно независимы.
\begin{defin}
k - высота корневого многочлена $(\mathcal A-\lambda_iI)^k$
\end{defin}
Ненулевые корневые векторы различных высот линейно независимы.\\
Если $(\mathcal A-\lambda_iI)^kx=0$, то $(\mathcal A-\lambda_iI)^{k-1}x\ne0$.
Таким образом, корневым вектором может быть либо 0, либо либо собственный, 
либо присоединенный вектор высоты $n-1$\\
$N_k=ker(\mathcal A-\lambda_iI)^k$\\
$N_1\subset N_2\subset...\subset N_q=N_{q+1}=N_{q+2}...$, то есть существует 
такой $q\in\mathbb Z$, что $(\mathcal A-\lambda_iI)^k$ - нильпотентный 
оператор\\
$N_1=ker(\mathcal A-\lambda_iI)=W_{\lambda_i}$ - собств. подпространство 
оператора А.\\
\begin{defin}
$dim(W_{\lambda_i})=s_i$ - геометрическая кратность\\
$dim(K_{\lambda_i})=m_i$ - алгебраическая кратность\\
$s_i\leqslant m_i$
\end{defin}
Если $S_i\leqslant m_i$, то матрица оператора имеет диагональный вид. 
\begin{theor}
Для любого расщепленного оператора существует базис, в котором его матрица
диагональна, причем количество клеток равно количеству собственных чисел.
\end{theor}




\subsection{Жорданова форма}
\begin{theor}
Пусть $\mathcal A\in L(\mathbb C^n,\mathbb C^n)$, и его характеристический
многочлен имеет вид $\triangle(\lambda)=(\lambda_1-\lambda)^{m_1}..
.(\lambda_p-\lambda)^{m_p},~\lambda_i\ne\lambda_j$. Тогда существует базис
$\{e\}$, в котором матрица оператора имеет квази-диагональную форму
\end{theor}
$$A=\begin{pmatrix}\boxed{A_1}&&0\\&\ddots&\\0&&\boxed{A_n}\end{pmatrix}$$
$$A_i=\begin{pmatrix}\boxed{J_{q_1}(\lambda_1)}&&0\\&\ddots&\\0&&\boxed
{J_{q_{s_i}}(\lambda_i)}\end{pmatrix}$$
где $J_{q_i}=\begin{pmatrix}\lambda_1&1&&\large{0}\\&\ddots&\ddots&1\\\large
{0}&&\ddots&\lambda_1\end{pmatrix}$\\
причем $m_i=q_1+...+q_{s_i}$\\
Количество клеток n-ого порядка равно $t_k=-n_{k-1}+2n_k-n_{k+1}=r_{k-1}-2r_
k+r_{k+1}$, где
$n_k=dim(N_k)=deg(\mathcal A-\lambda_iI)^k$, $r_k=rg(\mathcal A-\lambda_iI)^k$\\
\textbf{Доказательство.} 
1. По теореме \ref{raschep} о расщеплении, пространство $V=\mathbb C^n$ можно 
представить в виде прямой суммы корневых подпространств с размерностями, 
равными соответствующим алгебраическим кратностям:
$$V=W_1\oplus...\oplus W_p$$
2. Оператор $B_i=\mathcal A-\lambda_iI$, индуцированный на корневом 
подпространстве, по определению является нильпотентным. Значит, по теореме ,
корневое подпространство можно разложить в прямую сумму циклических подпространств.\\
3. Теперь заметим, что в базисе из собственных векторов оператор $B_i$, 
индуцированный на циклическом подпространстве, имеет вид 
$$B_i=\begin{pmatrix}0&1&&\large{0}\\&\ddots&\ddots&1\\\large{0}&&\ddots&0
\end{pmatrix}$$
Поскольку $\lambda_iI=diag(\lambda_i)$, то сам индуцированный оператор имеет
вид жордановой клетки $J(\lambda_i)$. Поскольку оператор является прямой суммой
операторов, индуцированных на цилических подпространствах корневых 
подпространтв, то его вид в этом базисе - жоданова форма. $\square$


\textbf{Следствие:} для собственных чисел оператора А имеет место
$\sum\limits^n\lambda_i=tr(\mathcal A)$, $\prod\limits^n\lambda_i=det(A)$.
Полученная форма оператора - жорданова, базис е - канонический жорданов базис\\
\begin{theor}
$A=CA_eC^{-1}$, где $A_e$ - жорданова форма, С состоит из координатных столбцов
собственных и присоединенных векторов.\end{theor}
\textbf{Доказательство.} Пусть $K_{\lambda_i}$ - корневое подпространство
оператора $\mathcal A$. Пусть $B=\mathcal A-\lambda_iI,~N_k=kerB^k,~n_k=dimN_k
,~r_k=rkB^n$. Построим $K_{\lambda_i}$. Найдем $q$, начиная с которого все ядра
$N_q$ совпадают с $K_{\lambda_i}$. 

Будем строить $K_{\lambda_i}$ начиная с подпространств $N_q...N_1$.
Пусть $f_1...f_{t_q}$ - векторы, дополняющие произвольный базис $N_{q-1}$ до
$N_q$. Их количество равно $t_q=n_{q}-n_{q-1}$. Возьмем векторы $B_{f_1}...B
_{f_{t_q}}$- векторы высоты $q-1$, и они линейно независимы над $n-2$. Дополним
их векторами $g_1...g_{t_{q-1}}\in N_{q-1}$. Векторы $B_{f_1}...B_{f_{t_q}}$, 
$g_1...g_{t_{q-1}}$ образуют базис в $N_{q-1}$. Их количество равно $n_{q-1}
-n_{q-2}$, $t_{q-1}=(n_{q-1}-n_{q-2})-(n_q-n_{q-1})$, следовательно $t_q=-n_q
-n_{q+1}+2n_q-n_q-1$. Выполним такие же построения для подпространств $N_{q-2}
...N_1$.
В $N_1\colon B^{q-1}f_1...B^{q-1}f_{t_q},~B^{q-2}g_1...B^{q-2}g_{t_{q-1}},~
B_{v_1}...B_{v_{t_2}}$, которые дополняются векторами $u_1...u_{t_1}$ до базиса
в $N_1$, и они линейно независимы.
Таким образом, за $q$ шагов получаем базис корневого подпространства $K_{x_i}$.
$\square$\\
\textbf{Пояснение.} Пусть $e_1...e_q$ - векторы первого столбца жордановой 
лестницы. Тогда
$$\begin{cases}e_1=B^{q-1}f_1\\e_2=B_{q-2}f_1\\\dots\\e_q=B^0f_1=f_1\end{cases}
\Rightarrow\begin{cases}Be_1=0\\Be_2=0\\\dots\\Be_q=0\end{cases}\Rightarrow
\begin{cases}(\mathcal A-\lambda I)e_1=0\\(\mathcal A-\lambda I)e_2=e_?\\\dots
		\\(\mathcal A-\lambda I)e_q=e_{q+1}\end{cases}\Rightarrow\begin{cases}
\mathcal Ae_1=\lambda_ie_1\\\mathcal Ae_2=e_1+\lambda_ie_2\\\dots\\\mathcal A
e_q=\lambda_ie_q+e_{q-1}\end{cases}$$
Этой группе векторов соответствуют ппервые q столбцов матрицы $\mathcal A|K_{\
lambda_i}$ в координатном базисе, и она имеет вид
$$\begin{pmatrix}\boxed{J_q(\lambda_i)}\\0\end{pmatrix}=\begin{pmatrix}\lambda
_i&1&&\large{0}\\&\ddots&\ddots&1\\\large{0}&&\ddots&\lambda_i\\--&--&--&--\\0
&0&\dots&0\end{pmatrix}$$




\subsubsection{Алгоритм нахождения жордановой формы и жорданова базиса для
матрицы $3\times3$}
\textbf{Вариант 1.} Пусть $f(\lambda)=(-1)^3(\lambda-\lambda_1)
(\lambda-\lambda_2)(\lambda-\lambda_3)$. Тогда 
$$A_e=\begin{pmatrix}\boxed{\lambda_1}&0&0\\0&\boxed{\lambda_2}&0\\0&0&
\boxed{\lambda_3}\end{pmatrix}$$
\textbf{Вариант 2.} Пусть $f(\lambda)=(-1)^3(\lambda-\lambda_1)^2(\lambda-\lambda_2)$.
Разберем случаи разного ранга матрицы:
\begin{itemize}
    \item $rk(A-\lambda_1E)=rkB_1=1$ следовательно, $S_1=n-rkB_1=3-1=2$ то есть
			две клетки и два собственных вектора плюс собственный вектор для
			$\lambda_2$: $A_e=\begin{pmatrix}\lambda_1&0&|&0\\0&\lambda_1&
			|&0\\--&--&-|&\\0&0&&\boxed{\lambda_2}\end{pmatrix}$
    \item $rk(A-\lambda_1E)=rkB_1=2$, $S_1=3-1=2$ - одна клетка, один вектор.
		    $A_e=\begin{pmatrix}\lambda_1&0&|&0\\0&\lambda_1&|&0\\--&-
			-&-|&\\0&0&&\lambda_2\end{pmatrix}$. $e_1$ - собственный 
			для $\lambda_1$, $e_2$ - присоединенный для $\lambda_1$ 
			высоты 1, $e_3$ - собственный для  $\lambda_2$
\end{itemize}
\textbf{Вариант 3.} Пусть $f(\lambda)=(-1)^3(\lambda-\lambda_1)^3$
Снова имеем два случая. 
\begin{itemize}
    \item $rk(A-\lambda_1E)=rkB_1=1$ следовательно, $S_1=3-2=2$ то есть две
			клетки и два собственных вектора  $\lambda_2$: $A_e=\begin{pmatrix}
			\lambda_1&0&|&0\\0&\lambda_1&|&0\\--&--&-|&\\0&0&&\boxed{\lambda_2}
	\end{pmatrix}$. 
    $e_1$ - собственный  $e_2$ - присоединенный $e_3$ 
    \item $rk(A-\lambda_1E)=rkB_1=2$, $S_1=3-2=1$ - одна клетка - вся матрица.
			$A_e=\begin{pmatrix}\lambda_1&0&0\\0&\lambda_1&0\\0&0&\lambda_2
			\end{pmatrix}$. $e_1$ - собственный $e_2$, $e_3$ присоединенный
\end{itemize}
 
\newpage
\section{Функции от матриц}
\subsection{Функции от жордановой формы}
Пусть $A$ - квадратная матрица, $f(\lambda)$ - какая-то скалярная функция.
Если это многочлен, то $f(A)=a_0E+a_1A+...+a_nA^n$
\begin{theor}\label{jord_function}
Если А приведена к жордановой форме, то $f(A)=Cf(A_e)C^{-1}$, где С - матрица,
составленная из столбцов жорданова базиса, при этом
\end{theor}
$$f(J_m(\lambda_0))=\begin{pmatrix}f(\lambda_0)&\frac{f'(\lambda_0)}{1!}&\dots&
\frac{f^{(m-1)}(\lambda_0)}{(m-1)!}\\0&f(\lambda_0)&\dots&\frac{f^{(m-2)}
(\lambda_0)}{(m-2)!}\\&\dots&\ddots&\\0&&&f(\lambda_0)\end{pmatrix}$$
\textbf{Доказательство.} В случае, если $A=\begin{pmatrix}\lambda_1&&\large{0}
\\&\ddots&\\\large{0}&&\lambda_n\end{pmatrix}$, то $$f(A)=\begin{pmatrix}f
(\lambda_1)&&\large{0}\\&\ddots&\\\large{0}&&f(\lambda_n)\end{pmatrix}$$\\
В общем случае: разложим функцию в рад Тейлора: $f(\lambda)=f(\lambda_0)+\frac
{f'(\lambda_0)}{1!}(\lambda-\lambda_0)+...+\frac{f^{(k)}(\lambda_0)}{k!}
(\lambda-\lambda_0)^k$
Тогда $f(J_m(\lambda_0))=f(\lambda_0)I+\frac{f'(\lambda_0)}{1!}I_m+...+
		\frac{f^{(k)}(\lambda_0)}{k!}I_m^k$, где $$I_m=J_m(\lambda_0)-
		\lambda_0I=\begin{pmatrix}0&1&&\large{0}\\&\ddots&\ddots&1\\\large{0}
		&&\ddots&0\end{pmatrix}_{m\times m}$$, причем при возведении в степень
				диагональ из единиц сдвигается вверх, поэтому $I_m^{m-1}=
				\begin{pmatrix}0&\dots&1\\\vdots&\ddots&\vdots\\0&\dots&0\end{pmatrix}$,
				$I_m^{\geqslant m}=0$

Если $f(\lambda)$ - произвольная функция, то $f(A)=g(A)$, где $g(\lambda_k)=
f(\lambda_k)$ - любой многочлен, который принимает значения равные $f$ на всех
собственных числах матрицы А.

\textbf{Пример.} Возьмем матричную экспоненту $e^A,~A=\begin{pmatrix}4&4\\-1&0
\end{pmatrix}$\\
Характеристический многочлен $\triangle(\lambda)=\begin{vmatrix}4-\lambda&4\\-
1&0-\lambda\end{vmatrix}=(\lambda-2)^2$, $\lambda_1=2$\\
$$B=A-\lambda_1E\begin{pmatrix}2&4\\-1&-2\end{pmatrix}\sim\begin{pmatrix}1&2\\
0&0\end{pmatrix}$$\\
$rkB=1\Rightarrow S_1=2-1=1$ - имеем одну клетку, один собственный вектор. 
Значит, $A_e=J_2(\lambda_1)=\begin{pmatrix}2&1\\0&2\end{pmatrix}$\\
Найдем собственный и присоединенный вектора. $\begin{pmatrix}1&2\\0&0\end{pmatrix}
\Rightarrow x_1=-2x_2\Rightarrow e_1=(-2,1)$ - собственный вектор, $e_{11}$ -
присоединенный вектор ($Bx=e_1$)\\
$$\begin{pmatrix}2&4&|&-2\\-1&-2&|&1\end{pmatrix}\sim\begin{pmatrix}1&2&|
				  &-1\\0&0&|&0\end{pmatrix}\Rightarrow x_1=1-2x_2$$
При $x_2=0$, $x_1=-1$, следовательно $e_{11}=(-1,0)$. Итак, 
$$C=\begin{pmatrix}-2&-1\\1&0\end{pmatrix},~C^{-1}=\begin{pmatrix}1&3\\-1&-2
\end{pmatrix}$$
$e^A=f(A)=Cf(A_e)C^{-1}=\begin{pmatrix}-2&-1\\1&0\end{pmatrix}\begin{pmatrix}
e^2&e^2\\-0&e^2\end{pmatrix}\begin{pmatrix}1&3\\-1&-2\end{pmatrix}$
\subsection{Теорема Гамильтона-Кэли}
\begin{theor}
(Гамильтона-Кэли)\\
Подстановка матрицы А в её характеристический многочлен дает 0.
\end{theor}
\textbf{Доказательство.} Поскольку матрица оператора подобна жордановой форме,
по теореме \ref{harakt_mnch_podob} их характеристические многочлены совпадают,
поэтому проведем доказательство для жордановых форм.

Пусть $f(\lambda)$ - характеристический многочлен матрицы оператора.
По теореме \ref{jord_function}, каждая жорданова клетка $m_0\times m_0$ для
собственного значения $\lambda_0$ имеет вид  
$$f(J_m(\lambda_0))=\begin{pmatrix}f(\lambda_0)&\frac{f'(\lambda_0)}{1!}&
\dots&\frac{f^{(m-1)}(\lambda_0)}{(m-1)!}\\0&f(\lambda_0)&\dots&\frac{f^{(m-2)}
(\lambda_0)}{(m-2)!}\\&\dots&\ddots&\\0&&&f(\lambda_0)\end{pmatrix}$$
Поскольку $\lambda_0$ - корень характеристического многочлена, на главной
диагонали стоят нули. Кроме того, собственное значение $\lambda_0$ - корень
многочлена кратности $m_0$, поэтому оно является корнем для всех многочленов 
$f'(\lambda),~f''(\lambda),~...,~f^{(m-1)}(\lambda)$ (по теореме, разобранной
в первом сесместре). Значит, каждая жорданова клетка в характеричтисечком 
многолене становится нулевой, откуда вся матрица - нулевая. $\square$




\newpage
\section{Линейные операторы униатарных (евклидовых) пространств}
\begin{defin}
Линейное отображение $f\colon V\to P$ называется линйеной формой или 
функционалом. Р может быть $\mathbb R$ или $\mathbb C$
\end{defin}
\textbf{Пример}ы отображений: все векторы переходят в ноль; в арифметическом
конечномерном пространстве вектор отображается в первую координату.\\
\begin{defin}Если $\{e\}$ - базис в V, то линейная форма $f$ однозначно 
определяется числами $\alpha_i=f(e_i)$. Они называются коээфициенты линейной
формы f в базисе $\{e\}$\end{defin} 
Если $x=x_1e_1+...+x_ne_n$, то $f(x)=x_1\alpha_1+...+x_n\alpha_n$\\
Заметим, что пространство линейных форм само является линейным пространством, 
поскольку $(f_1+f_2)(x)=f_1(x)+f_2(x)$, $f(\alpha x)=\alpha f(x)$. В связи
с этим вводится
\begin{defin}
Линейное пространство $L(V,P)$ называют двойственным к V пространством и
обозначают $V^*$
\end{defin}
Для конечных размерностей, линейное пространство изоморфно двойственному. 
Чтобы установить это, нам потребуется 
\begin{theor}
В евклидовом (унитарном пространстве) для функционала f сущеуствует и 
единственен вектор h такой, что $\forall x\in V\colon f(x)=(x,h)$
\end{theor}
\textbf{Доказательство.} Используем ортонормированный базис $\{e\}$ и его 
коэффиценты $\{\alpha\}$ для функционала $f$. Положим $h=\sum\limits^{n}_{i=1}
\overline{\alpha_i}e_i$ и $x=\sum\limits^{n}_{i=1}x_ie_i$.
Тогда имеем $f(x)=f(\sum\limits^{n}_{i=1}x_ie_i)=\sum\limits^{n}_{i=1}x_if(e_i)
=\sum\limits^{n}_{i=1}x_ie_i=\sum\limits^{n}_{i=1}x_i\alpha_i$. Но скалярное 
произведение равно
$(x,h)=(\sum\limits^{n}_{i=1}x_ie_i,\sum\limits^{n}_{i=1}\overline{\alpha_i}e_i)
=\sum\limits^{n}_{i=1}x_i\overline{\overline{\alpha_i}}=\sum\limits^{n}_{i=1}
x_i\alpha_i$, 
что и требовалось доказать $\square$\\
Если базис не ортонормирован, то в векторном виде имеем $(x,h)=f(x)=x\Gamma h$,
где $\Gamma$ - матрица Грама для этого базиса.\\
Эта теорема позволяет построить изоморфизм, взяв какой-нибудь ненулевой вектор
и положив $\varphi_h\colon V\to V^*$, $\varphi_h(x)\mapsto(x,h)$
\subsection{Сопряженный оператор}
Пусть $V,W$ - унитарные евклидовы пространства. Если $\mathcal{A,B}\in L(V,W)$
и $(\mathcal Ax,y)=(\mathcal Bx,y)$, то $\mathcal{A=B}$
\begin{defin}
Отображение $\mathcal A^*\in L(W,V)$ - сопряженный оператор для $\mathcal{A}
\in L(V,W)$, если $(\mathcal Ax,y)=(x,\mathcal A^*y)$
\end{defin}
Рассмотрим основные свойтства.
\begin{theor}
Сопряженный оператор линеен - следует из линейности скалярного произведения
\end{theor}
\begin{theor}
Для всякого оператора существует единственный сопряженный оператор
\end{theor}
\textbf{Доказательство.} Возьмем ортонормированный базис $\{e\}$. Тогда любой
вектор выражвется как $x=\sum\limits^{n}_{i=1}x_ie_i=\sum\limits^{n}_{i=1}
(x,e_i)e_i$. Тогда $\mathcal Ax=\sum\limits^{n}_{i=1}(x,e_i)\mathcal Ae_i$ и
следовательно $(\mathcal Ax,y)=\sum\limits^{n}_{i=1}(x,e_i)(\mathcal Ae_i,y)$
Покажем, что оператор $\mathcal B\in L(W,V)$, удовлеторяющий свойству $\mathcal
By=\sum\limits^{n}_{i=1}(y,\mathcal Ae_i)e_i$ - сопряженный к $\mathcal A$:
$(x,\mathcal By)=\sum\limits^{n}_{i=1}\overline{(y,\mathcal Ae_i)}(x,e_i)=
\sum\limits^{n}_{i=1}(\mathcal Ae_i,y)(x,e_i)$ (поскольку в унитарных 
пространствах скалярное произведение коммутативно в композиции с комплексным 
сопряжением). Итак, $(\mathcal Ax,y)=(x,\mathcal By)$, что и требовалось 
доказать. $\square$\\
\textbf{Свойства сопряженного оператора}\\
1,2 - линейность относительно сопряжения\\
3. Антикоммутативность относительно сопряжения\\
4. $(A^{-1})^*=(A^*)^{-1}$\\
5. $(A^*)^*=A$


\subsection{Биортогональные базисы}
\begin{defin}
Системы векторов $\{x\}$ и $\{y\}$ из унитарного пространства называются 
биортогональными, если выполняется соотношение
\end{defin}
$$(x_i,y_j)=\delta_{ij}=\begin{cases}1,~i=j\\0,~i\ne j\end{cases}$$где
$\delta_{ij}$ - символ Кронекера.\\
Биортогональные системы векторов линейно независимы. \\
В n-мерном векторном пространстве биортогональные системы векторов мощности
n образуют пару биортогональных базисов. \\
Ортонормированный базис биортогонален сам себе.
\begin{theor}
Для любого базиса $\{e\} $евклидова унитарного пространства существует 
единственный биортогональный базис $\{f\}$. 
\end{theor}
\textbf{Доказательство.} $\forall j,~f_j\perp e_i$ кроме случая $i=j$. 
Следовательно, $f_j$ принадлежит ортогональному дополнению $L_j$ линейной 
оболочки всех векторов базиса $\{e\}$, кроме j-того. Очевидно, $dimL_j=1$. 
Значит, если g - какой-либо базисный вектор в $L_j$, то $f_j-\alpha g,~
\alpha\in\mathbb C$. Так как $(f_j,e_j)=1$, то $\alpha=\frac1{g,e_j}$ и 
соотвественно $f_j=\frac g{(g,e_j)}$ - следовательно, для каждого j вектор 
определен однозначно, то есть построен единственный биортогональный базис.
$\square$
\begin{theor}\label{vparebiortba}
В биортогональных базисах $\{e\}$ и $\{f\}$ унитарного евклидова пространства
для линейных автоморфизмов $\mathcal A$ и $\mathcal A^*$ имеет место 
соотношение $(\mathcal A^*)_f=(\mathcal A_e)^H$
\end{theor}
\textbf{Доказательство.} Пусть $A_e=(a_{ij})$, $A^*_f=(b_{ij})$ - квадратные
матрицы операторов. Тогда $\mathcal Ae_i=\sum\limits^n_{k=1}a_{ki}e_k$,
$\mathcal A^*f_i=\sum\limits^n_{k=1}b_{ki}f_k$. Значит, скалярное
произведение $(\mathcal Ae_i,f_i)=(\sum\limits^n_{k=1}a_{ki}e_k,f)=a_{ii}$,
значит, $(\mathcal Ae_j,f_i)=a_{ij}$

C другой стороны, $(\mathcal Ae_i,f_i)=(e_j,\mathcal A^*f_i)=(c_j,
\sum\limits^n_{k=1}b_{ki}f_k)=\sum\limits^n_{k=1}\overline{b_{ki}}(e_j,f_k)=
\overline{b_{ji}}$, следовательно $a_{ij}=\overline{b_{ji}}$, что и требовалось
$\square$\\
\textbf{Следствие 1.} Если базис $\{e\}$ ортонормирован, то $(\mathcal A^*)_e=
(A_e)^H$ (если базис не ортонормирован, то нужен ещё оператор перехода)\\
\textbf{Следствие 2.} Для всех линейных автоморфизмов: $detA^*=\overline{detA}$
, $rkA=rkA^*$ 
\begin{theor}
$ker\mathcal A=im^\perp\mathcal A^*$, $ker\mathcal A^*=im^\perp\mathcal A$
\end{theor}
\textbf{Доказательство.}(только для первого равенства). $\forall x\in 
ker\mathcal A,~y\in im\mathcal A*$ имеет место $\mathcal Ax=0,~\mathcal
A*y_1=y$. Тогда $(x,y)=(x,\mathcal A^*y_1)=(\mathcal Ax,y_1)=(0,y_1)=0$.
Значит, $ker\mathcal A\subset im^\perp\mathcal A^*$. С
другой стороны, $dim(ker\mathcal A)=dimV-dim(im\mathcal A)$, или $dimV-
dim(im\mathcal A^*)=dim(im^\perp\mathcal A^*)$, следовательно, $ker\mathcal 
A=im^\perp \mathcal A^*$ $\square$
\begin{theor}
Если подпространство L унитарного евклидова пространства V инвариантно
относительно оператора $\mathcal A$, то ортогональное дополнение $L^\perp$ 
инвариантно относительно $\mathcal A^*$
\end{theor}
\textbf{Доказательство.} Пусть $x\in L,~y\in L^\perp$. Тогда 
$(\mathcal Ax,y)=0$, но $(\mathcal Ax,y)=(x,\mathcal A^*y)=0$, и так как
$\mathcal A^*y\in L^\perp$, то $L^\perp$ инвариантно относительно
$\mathcal A^*$ $\square$
\subsection{Нормальный оператор}
В данном разделе векторное пространство унитарно и евклидово.
\begin{defin}
Линейный автоморфизм $\mathcal A$ векторного пространства называется нормальным
оператором, если $\mathcal A\mathcal A^*=\mathcal A^*\mathcal A$\\
Квадратная матрица А называется нормальной, если $AA^H=A^HA$
\end{defin}
Согласно теореме (\ref{vparebiortba}), оператор нормален тогда и только тогда,
когда при любом ортонормированном базисе оператор нормален.
\begin{theor}
Собственный вектор нормального оператора $\mathcal A$, отвечающий собственному
значению $\lambda$, является собственным вектором сопряженного оператора
$\mathcal A^*$, отвечающего собственному значению $\overline{\lambda}$
\end{theor}
\textbf{Доказательство.} Если $\mathcal A$ - нормален, то $\mathcal A-\lambda I$
- тоже нормален. Пусть х - собственный вектор для $\lambda$. Тогда
$(\mathcal A-\lambda I)x=0$, $((\mathcal A-\lambda I)x,(\mathcal
A-\lambda I)x)=0$, $(x,(\mathcal A-\lambda I)^*(\mathcal A-\lambda I)x)=0$,
$((\mathcal A-\lambda I)^*x,(\mathcal
A-\lambda I)^*x)=0$. Следовательно, $(\mathcal A-\lambda I)^*x=0$, то есть 
$(\mathcal A^*-\overline{\lambda} I)=0$, то есть
$\mathcal A^*x=\overline{\lambda}x$, что и требовалось доказать $\square$\\
\textbf{Следствие 1.} Если оператор нормальный, то
$ker\mathcal A=ker\mathcal A^*$\\
\textbf{Следствие 2.} Если оператор нормален, то
$ker\mathcal A=im^\perp\mathcal A$, $ker\mathcal A^*=im^\perp\mathcal A^*$
\begin{theor}\label{sobvecpoparort}
Собственые векторы нормального оператора отвечающие различным собственным 
значениям, попарно ортогональны
\end{theor}
\textbf{Доказательство.} Пусть $\mathcal Ax=\lambda x$, $\mathcal Ay=\mu x$, 
$\lambda\ne\mu$. Тогда $(\mathcal Ax,y)=(\lambda x,y)=\lambda(x,y)$. С другой
стороны, $(\mathcal Ax,y)=(x,\mathcal
A^*y)=(x,\overline{\mu}y)=\mu(x,y)$. Но по условию собственные числа различны,
значит, векторы ортогональны. $\square$
\begin{theor}(Шура)\\
Для любого автоморфизма векторного пространства существует ортонормированный
базис, называемый базисом Шура, в котором матрица оператора имеет верхний 
треугольный вид
\end{theor}
\textbf{Доказательство.} Найдем жорданов базис, затем применим процесс
ортагонализации по Граму-Шмидту. Полученный базис - базис Шура. $\square$
\begin{theor}(критерий нормальности)\\
Оператор нормален тогда и только тогда, когда существует базис из собственных
векторов этого оператора.
\end{theor}
\textbf{Доказательство.} Небходимость. Пусть $\mathcal A$ наормален и $\{e\}$ 
- его базис Шура. Значит, матрицы $A_e$ и $A_e^H$ треугольные. В силу 
нормальности А и ортонормированности базиса Шура эти две матрицы
коммутируют: $A_eA_e^H=A_e^HA_e$. Сравнивая диагональные элементы полученных
матриц, стоящих слева и справа. получим, что $A_e$ имеет диагональную форму.
Значит, базис Шура есть базис из собственных векторов $\mathcal A$\\
Достаточность. Пусть $\{e\}$ - базис из собственных векторов оператора 
$\mathcal A$. Тогда матрица вектора и эрмитово сопряженная к ней - 
диагональные. Так как диагональные матрицы коммутируют, то оператор нормальный.
$\square$\\
\textbf{Следствие.} В унитарном пространстве нормальный оператор и его
сопряженный оператор имеет ортонормированный базис из собственных векторов. 
\begin{theor}(обратная к теореме (\ref{sobvecpoparort}))
Если собственный вектор оператора является собственным вектором его 
сопряженного оператора, то оператор нормальный.
\end{theor}

\subsection{Унитарно-подобные матрицы}
\begin{defin}
Матрицы А и В называются подобными унитарно (ортогонально), если
$B=Q^{-1}AQ$ и $Q$ - унитарна (ортогональна; т.е. $QQ^H=Q^HQ=E$)
\end{defin}
Иначе говоря, отношение подобия для двух матриц выглядит как $B=Q^HAQ$
(в евклидовых пространствах $B=Q^TAQ$). Очевидно, что две матрицы являются
подобными тогда и
только тогда, когда они являются матрицами одного и того же оператора в
унитарном (евклидовом) пространстве в ортонормированном базисе.
\begin{theor}
Квадратная комплексная матрица нормальна, когда она унитарно подобна 
диагональной матрице.
\end{theor}
\textbf{Доказательство} следует из определения унитарности. $\square$
\subsection{Унитарный оператор}
\begin{defin}
Линейный автоморфизм U, действующий в унитарном (евклидовом) пространстве,
называется унитарным (ортогональным), если $U^*U=UU^*=I$
\end{defin}
\textbf{Свойства унитарного оператора U:}\\
1. U нормален\\
2. $U^*=U^{-1}$\\
3. $|detU|=1$\\
4. Оператор унитарен (ортогонален), если в любом ортонормированном базисе его
матрица унитарна (ортогональна)
\begin{theor}(критерий унитарности)\\
Следующие утверждения эквивалентны:\\
1. U унитарен\\
2. $(Ux,Uy)=(x,y)$\\
3. $|Ux|=|x|$\\
4. U сохраняет ортонормированность базиса
\end{theor}
\textbf{Доказательство}\\
$1\Rightarrow2$. Так как $UU^*=I$, то $(Ux,Uy)=(x,U^*Uy)=(x,y)$\\
$2\Rightarrow3$. $|Ux|=\sqrt{(Ux,Ux)}=\sqrt{(x,x)}=|x|$\\
$2,3\Rightarrow4$. Очевиднo.\\
$4\Rightarrow1$. Пусть U - оператор, сохраняющий ортонормированность. Тогда
$\square$ \\
Заметим вскользь, что униатрный оператор на любом подпространстве индуцирует
унитарный оператор. 
\begin{theor}\label{specharortop}(спектральная характеристика унитарного 
		оператора)\\
Нормальный оператор является унитарным тогда и только тогда, когда все его
собственные значения равны по модулю единице.
\end{theor}
\textbf{Доказательство.} Пусть $Ux=\lambda x$. 
Тогда $(x,x)=(Ux,Ux)=(\lambda x,\lambda x)=\lambda\overline\lambda(x,x)$,
откуда $\lambda\overline\lambda=1$, 
то есть $|\lambda|=1$.\\
Обратно, пусть U - нормальный оператор и $\{e\}$ - ортонормированный базис,
векторы которого являются собственными векторами оператора.
Тогда произвольный вектор $x=\sum\limits^{n}_{i=1}x_ie_i$,
$Ux=\sum\limits^{n}_{i=1}\lambda_ix_ie_i$.
Следовательно, $(Ux,Ux)=\sum\limits^{n}_{i=1}|x_i|^2|\lambda_i|^2=(x,x)$, то
есть оператор унитарен. $\square$
\subsubsection{Каноническая форма матрицы унитарного оператора}
Поскольку унитарный оператор нормален, то найдется ортонормированный базис, в
котором матрица
оператора будет диагональной, причем ненулевые элементы будут равны по модулю
единице. \\
Итак, пусть $Q$ - ортогональный оператор в евклидовом пространстве $E$. По 
теореме (\ref{specharortop}), $\lambda=\pm1$ и $detQ=\pm1$. Также, в любом
ортонормированном базисе $\{e\}$, $Q_e^{-1}=Q_e^T$.\\
\textbf{Пример 1.} В $E=\mathbb R^1$, $Q_e=(\pm1)$;\\
\textbf{Пример 2.} В $E=\mathbb R^2$, $Q_e=\begin{pmatrix}a&b\\\mp b&\pm
a\end{pmatrix}$ (в зависимости от знака определителя).\\
Введем два очень важных типа линейных операторов в евклидовом пространстве.
\begin{defin}\makebox{}\\
\textbf{Простым вращением} наывается оператор, матрица которого имеет вид
$$diag(1...1,\Phi,1...1)$$
\textbf{Простым отражением} называется оператор, матрица которого имеет вид 
$$diag(1...1,-1,1...1)$$
\end{defin}
Геометрически, простое вращение осуществляет поворот вектора на угол $\varphi$.
Из определений также следует, что простое вращение и простое отражение -
ортогональные операторы. Очевидно также, что простое вращение
поворачивает какую-плоскость, и оставляет инвариантным $(n-2)$-мерное 
подпространство, а простое отражение меняет направление векторов одномерного 
подпространства, и не меняет $(n-1)$-мерное подпространство.
\begin{theor}
Любой ортогональный оператор может быть представлен в виде произведения 
простых вращений и простых отражений. 
\end{theor}
\textbf{Доказательство.} Поскольку ортогональный оператор сохраняет скалярное
		произведение, то тем самым он сохраняет длину вектора. Если
		$\Phi=\begin{pmatrix}a&b\\c&d\end{pmatrix}$ - его матрица, то условие
		сохранения длины вектора $(x,y)^T$ эквивалентно
		$(ax+by)^2+(cx+dy)^2=x^2+y^2$, откуда $a^2+c^2=b^2+d^2=1,~ab+cd=0$. 
		Параметризуя через угол $\varphi$, имеем $\Phi=\begin{pmatrix}
				\cos\varphi&-\sin\varphi\\\sin\varphi&\cos\varphi\end{pmatrix}$ 
		или $\Phi=\begin{pmatrix}\cos\varphi&\sin\varphi\\\sin\varphi&-
		\cos\varphi\end{pmatrix}$. Геометрически, первый вариант соответствует
		повороту на угол $\varphi$, а второй - композиция поворота на угол
		$\varphi$ и зеркального отражения относительно подпространства
		$L((1,0)^T)$. Поскольку этим исчерпываются ортогональные преобразования, 
		теорема доказана. $\square$
\begin{theor}
Для любого ортогонального оператора Q в евклидовом пространстве,
найдется ортонормированный базис $\{e\}$, в котором его матрица имеет 
квази-диагональный вид, то есть состоит из клеток вида $(\pm1)$ и
$\Phi=\begin{pmatrix}\cos\varphi&-\sin\varphi\\
\sin\varphi&\cos\varphi\end{pmatrix}$ на главной диагонали:
\end{theor}
$$Q_e=\begin{pmatrix}1&&&&&&&&\\
&\ddots&&&&&&&\\
&&1&&&&&&\\
&&&-1&&&&&\\
&&&&\ddots&&&&\\
&&&&&-1&&&\\
&&&&&&\Phi&&\\
&&&&&&&\ddots&\\
&&&&&&&&\Phi\end{pmatrix}$$
Такой вид также называют \textbf{канонической формой ортогонального 
оператора}.\\
\textbf{Доказательство}. Достаточно рассмотреть случай одномерного и 
		двумерного пространства, все остальные операторы можно получить
		прямой суммой одномерных и двумерных. В одномерном случае ортогональный
		оператор есть умножение на $\pm1$. В двумерном случае, как мы показали
		выше, любой ортогональный оператор есть либо простое вращение, либо
		простое отражение. Матрица вращения в любом ортонормированном базисе
		имеет вид $\Phi$, а для отражения можно подобрать такой 
		ортонормированный базис, в котором его матрица имеет вид
		$\begin{pmatrix}1&0\\0&-1\end{pmatrix}$.
$\square$\\


\subsection{Самосопряженный оператор}
\begin{defin}
Линейный автоморфизм $\mathcal A$ в унитарном (евклидовом) пространстве 
называется самосопряженным, если $\mathcal A=\mathcal A^*$, то есть
$(\mathcal Ax,y)=(x,\mathcal Ay)$
\end{defin}
В униатарном пространстве самосопряженный оператор называют эрмитовым 
(поскольку он инвариантен относительно эрмитова сопряжения; кстати, именно 
эрмитовым операторам соответствуют наблюдаемые величины квантовой механики в
формулировке фон Неймана), в евклидовых - симметричным.\\
\textbf{Свойства самосопряженного оператора U:}\\
1. U нормален.\\
2. $U^H=U$\\
3. Самосопряженность эквивалентна тому, что в любом ортонормированном базисе
любая матрица является самосопряженной.\\
4. Определитель U - действительное число, даже если U - оператор в 
\textit{унитарном} пространстве\\
5. Если подпространство инвариантно относительно U, то его ортогональное 
дополнение также инвариатно относительно U\\
6. На любом инвариантном подпространстве самосопряженный оператор индуцирует 
самосопряженный оператор. 
\begin{theor}
Нормальный оператор в унитарном (евклидовом) пространстве является 
самосопряженным тогда и только тогда, когда все его собственные значения
вещественны. 
\end{theor}
\textbf{Доказательство}. 
Пусть $\mathcal A$ - самосопряженный нормальный оператор и
$\mathcal Ax=\lambda x$. Тогда $(\mathcal Ax,y)=(\lambda x,y)=\lambda(x,y)$.
С другой стороны, по нормальности имеем $(\mathcal Ax,y)=(x,\mathcal
Ay)=\overline{\lambda}(x,y)$, откуда имеем $\overline{\lambda}=\lambda$, то
есть собственное число вещественно. \\
В другую сторону. Пусть оператор нормален и все его собственные значения 
вещественны. Возьмем
ортонормированный базис и представим вектор х в виде $\sum x_ie_i$  Далее,
$\mathcal Ax=\mathcal A\sum x_ie_i=\sum x_i\lambda_ie_i$.  C другой стороны,
$\mathcal A^*x=\sum x_i\overline{\lambda_i}e_i$ Но по условию все коэффициенты
$\lambda_i$ вещественные, то есть $\mathcal A=\mathcal A^*$, то есть оператор 
самосопряженный. $\square$\\
\textbf{Следствие 1.} Самосопряженный оператор имеет ровно $n$ собственных 
значений в $n$-мерном пространстве.\\
\textbf{Следствие 2.} Если $\mathcal A$ - самосопряженный оператор в $n$-мерном
пространстве, то  существует ортонормированный базис $\{e\}$, в котором матрица
оператора имеет вещественную диагональную форму  
\begin{theor}
Собственные векторы самосопряженного оператора, отвечающие различным собственным
значениям, являются ортогональными.
\end{theor}
\textbf{Доказательство.} Теорема следует из нормальности самосопряженного 
оператора. $\square$\\
\textbf{Следствие.} Из собственных векторов самосопряженного оператора можно
построить базис. 
\textbf{Пример.} Пусть 
$$A=\begin{pmatrix}11&2&-8\\2&2&10\\-8&10&5\end{pmatrix}$$
Найдем характеристический многочлен
$$\triangle(\lambda)=|A-\lambda E|=(\lambda-18)(\lambda-9)(\lambda+9)$$
Теперь найдем следующие матрицы
$$A_1=A-\lambda_1E\sim\begin{pmatrix}1&-8&5\\0&2&-1\\0&0&0\end{pmatrix}$$
Решаем систему $Ae_1=0$, имеем $2x_2=x_3$; получаем вектор $e_1=(-2,1,2)$. 
Также поступаем с другими собственными числами оператора. Из полученных 
векторов составляем матрицу С и матрицу А в базисе е:
$$C=\begin{pmatrix}-2&2&1/2\\1&2&-1\\2&1&1\end{pmatrix},~~A_e=
\begin{pmatrix}18&0&0\\0&9&0\\0&0&-9\end{pmatrix}=C^{-1}AC$$
Теперь отнормирвем векторы и составим из них матрицу U:
$$e_1'=\frac{e_1}{|e_1|}=\frac13(-2,1,2)$$
$$U=\frac13C=\frac13\begin{pmatrix}-2&2&1/2\\1&2&-1\\2&1&1\end{pmatrix}$$
Полученная матрица ортогональна: $U^{-1}=U^T$





\newpage
\section{Билинейные и квадратичные формы}
\subsection{Линейные формы}
\begin{defin}
Линейная форма (функционал) --- функция $f\colon V\to P$, определенная на
векторном пространстве V над полем Р и удовлетворяющая условиям линейности
\end{defin}
1. $f(x+y)=f(x)+f(y)$\\
2. $af(x)=f(ax)$\\
\textbf{Примеры.} След матрицы - линейная форма на пространстве матриц;
дифференцирование - линейная форма на пространстве дифференцируемых функций;
определенное интегрирование на отрезке - линейная форма на пространстве
непрерывных функций этого отрезка. 
\begin{defin}
Пусть $\{e\}$ - базис пространства V. Строка F называется \textbf{матрицей 
линейной формы} f в базисе $\{e\}$, если для вектора x, выраженного в базисе
$\{e\}$ столбцом X, имеет место
\end{defin}
$$f(x)=FX$$
Таким образом, действие линейной формы однозначно определяется её действием на
базисные векторы. Компоненты вектора $F$ называются коэффициентами формы в 
данном базисе $\{e\}$.
\begin{theor}
Пусть C - матрица перехода от базиса $\{e\}$ к $\{e'\}$. Тогда матрицы $F$ и 
$F’$ линейной формы $f$ в этих базисах связаны соотношением $F'=FC$.
\end{theor}
\textbf{Доказательство.} Пусть $X,~X'$ - представления вектора $x$ в базисах
$\{e\}$ к $\{e'\}$ соответственно. Тогда, поскольку $X=CX'$, имеем $f(x)=FX=F
'X'=FCX'$, откуда $F'=FC$. $\square$

\subsection{Билинейные формы}
\begin{defin}
Пусть V - линейное пространство над полем P. Отображение $\mathcal A(x,y)
\colon V\times V\to P$ называется билинейной формой, если для любых $x,y\in V$: 
\end{defin}
1. $\mathcal A(x+z,y)=\mathcal A(x,y)+\mathcal A(z,y)$\\
2. $\mathcal A(\alpha x,y)=\alpha\mathcal A(x,y)$\\
3. $\mathcal A(x,z+y)=\mathcal A(x,y)+\mathcal A(x,z)$\\
4. $\mathcal A(x,y\alpha)=\alpha\mathcal A(x,y)$\\
Иначе говоря, билинейная форма линейна по обеим переменным.
\begin{defin}
Билинейная форма $\mathcal A(x,y)$ называется симметричной, если 
$\mathcal A(x,y)=\mathcal A(y,x)$.
\end{defin}
\textbf{Примеры} билинейных форм: \\
1. Скалярное произведение - билинейная симметрическая форма\\
2. Если $f,g$ - линейая форма, то $\mathcal A(x,y)=f(x)g(y)$ - симметричная 
билинейная форма\\
3. В n-мерном пространстве V с базисом $\{e\}$ имеет вид $\mathcal A(x,y)=
\mathcal A(\sum_i x_ie_i,\sum_j y_je_j)=\sum_i\sum_jx_iy_j\mathcal A(e_i,e_j)$.
Если
обозначить $\mathcal A(e_i,y_j)=a_{ij}$, то $\sum_i\sum_jx_iy_ja_{ij}$ - 
\textbf{общий вид билинейной формы}. Значит, \textbf{любая билинейная форма
определяется некоторой квадратной матрицей} в определенном базисе
\begin{theor}
Пусть V - линейное пространство над P, $\{e\}$ - базис в V. Для любых чисел 
$a_{ij}\in P,~i,j\in\{1...n\}$ найдется и притом единственная билинейная форма
$\mathcal A(e_i,e_j)=a_{ij}$
\end{theor}
\textbf{Доказательство} существования следует из примера 3. Докажем 
единственность. Пусть $\mathcal B(e_i,e_j)$ - другая билинейная форма. 
Выразим эту
форму: $\mathcal B(x,y)=\mathcal B(\sum_i x_ie_i,\sum_j y_je_j)=
\sum_i\sum_jx_iy_j\mathcal B(e_i,e_j)=\sum_i\sum_jx_iy_ja_{ij}$, откуда
$\mathcal A=\mathcal B$. $\square$\\
В векторном виде, $\mathcal A(x,y)=x_e^TA_ey_e=y_e^TA^Tx_e$, где $A_e=(a_{ij})$
\begin{theor}
Произвольная матрица $n\times n$ является матрицей единственной билинейной 
формы в заданном базисе.
\end{theor}
\textbf{Доказательство} - см рассуждение выше. $\square$

Эти теоремы устанавливают естественную биекцию между билинейными формами 
n-мерного пространства и матрицами размера $n\times n$. 
\begin{theor}
Матрицы билинейной формы $\mathcal A(x,y)$ в базисах $\{e\}$ и $\{f\}=\{eC\}$ 
связаны соотношением $A_f=C^TA_eC$ (С - матрица перехода между базисами)
\end{theor}
\textbf{Доказательство.} $\mathcal A(x,y)=x_e^TA_ey_e$. Так как
$x_e=Cx_f,~y_e=Cy_f$, то $\mathcal A(x,y)=x_f^TC^TA_eCy_f=x_f^TA_fy_f$
$\square$\\
\textbf{Следствие.} $rkA_e=rkA_f$
\begin{theor}
Билинейная форма симмметрична, если её матрица в любом базисе симметрична. 
\end{theor}
\textbf{Доказательство}. $\mathcal A(x,y)=x_e^TA_ey_e=y_e^TA^T_ex_e$
С другой стороны, $\mathcal A(x,y)=y_e^TA_ex_e$
Значит, если $\mathcal A(x,y)=\mathcal A(y,x)$, то $A^T=A$, то есть матрица 
симметрична. 
\begin{defin}
Ранг билинейной формы - ранг её матрицы в любом базисе. Если ранг формы меньше
размерности пространства, то форма называется вырожденной. 
\end{defin}
\begin{theor}
Билинейная форма $\mathcal A(x,y)$ является вырожденной тогда и только тогда,
когда существует ненулевой вектор х такой, что
\end{theor}
$$\mathcal A(x,y)=0~~\forall y\in V$$
\textbf{Доказательство.} Пусть $\{e\}$ - базис и $A_e$ - матрица билинейной 
формы в этом базисе. Тогда равенство нулю равносильно системе 
$\mathcal A(x,e_j)=0$. Учитывая
разложение вектора $x$ на базисные, получим $\sum_ix_i\mathcal A(e_i,e_j)=0$,
то есть  получили СЛАУ $\sum_ia_{ij}x_i=0$, которая будет иметь ненулевое
решение только когда матрица вырожденная. Значит, билинейная форма вырождена.
$\square$
\subsection{Квадратичные формы}
\begin{defin}
Пусть $\mathcal A(x,y)$ - симметричная билинейная форма в пространстве V над
полем P. Квадратичной формой называется отображение $\mathcal A\colon V\to P$,
которое ставит в соответствие вектору число $\mathcal A(x,x)$
\end{defin}
Билинейная форма $\mathcal A(x,y)$ называется полярной к квадратичной форме 
$\mathcal A(x,x)$
\begin{theor}
Полярная билинейная форма для любой квадратичной формы определена однозначно.
\end{theor}
\textbf{Доказательство.} Следует из формулы
$$\mathcal A(x,y)=0,5[\mathcal A(x+y,x+y)-\mathcal A(x,x)-\mathcal A(y,y)]
\quad\square$$
Матрица квадратичной формы в базисе $\{e\}$ является матрицей полярной к ней
билинейной формы.

\textbf{Свойства матрицы квадратичной формы}\\
1. Симметричность в любом базисе\\
2. Любая симметричная матрица является матрицей единственной квадратичной формы
в заданном базисе\\
3. В двух базисах $\{e\}$ и $\{f\}=\{eC\}$ матрицы связаны соотношением
$A_f=C^TA_eC$\\
4. В любом базисе квадратичная форма имеет вид $\mathcal A(x)=
\sum\limits_i^n\sum\limits_j^na_{ij}x_ix_j,~~a_{ij}=a_{ji},~x=(x_1...x_n)^T$\\
В векторных обозначениях: $\mathcal A(x)=x_e^TA_ex_e$
5. Ранг квадратичной формы определется её матрицей в любом базисе: 
$rk\mathcal A(x)=rkA_e$; $\mathcal A(x)$ является вырожденной квадратиной
формой, если её матрица вырождена.

\subsection{Канонический вид квадратичной формы}
Мы хотим привести матрицу квадратичной формы к красивому виду, изменяя
подходящим образом базис пространства V.
 \begin{defin}
 Базис $\{e\}$ называют каноническим базисом квадратичной формы, если её 
 матрица в этом базисе имеет диагональный вид
 \end{defin}
 $$A_e=diag(\lambda_1,...,\lambda_n)$$
 В этом случае квадартичная форма будет иметь вид
 $\mathcal A(x)=\lambda_1x_1^2+...+\lambda_nx_n^2$.
 Если $rk\mathcal A(x)<dimV$, то некоторые элементы будут нулевые
 (их можно расположить внизу матрицы).
 \begin{defin}
 Нормальный канонический вид - $\mathcal A(x)=\pm1 x_1^2+...+\pm1 x_r^2$
 \end{defin}
 


 \begin{theor} (о методе Лагранжа)\\
 Для любой квадратичной формы существует канонический базис.
 \end{theor}
 \textbf{Доказательство.} Пусть имеется некоторый базис $\{e\}$ в $V$ и в этом
 базисе оператор имеет вид $\mathcal A(x)=A_e$. Пусть $g(x_1,...x_n)=
 \sum\limits_i^n\sum\limits_j^na_{ij}x_ix_j$. Далее, пусть $x_e=Cx_f$, $f=eC$ -
 переход к новому базису $\{f\}$. 
 
 Пусть $A_e\ne0$. Обозначим через $\Delta_k$ угловые миноры порядка $k$:
 $\Delta_k=M^{1,...,k}_{1,...,k},~k\in\{1..n\}$. Положим по определению
 $\Delta_0=1$.
 
 \textbf{1.} Рассмотрим случай, когда $\Delta_k\ne0$. Первый шаг основан на 
 том, что $\Delta_1=a_{11}\ne0$. Тогда соберем все слагаемые, содержащие $x_1$,
 в многочлен $g(x)$, и
 выделим полный квадрат; в результате получим
 $g(x_1,...x_n)=a_{11}x_1^2+2\sum\limits_{k=2}^na_{1k}x_1x_k+
 \sum\limits_{i=2}^n\sum\limits_{j=2}^na_{ik}x_ix_j=a_{11}(x_1+
 \sum\limits^n_{k=2}\frac{a_{1k}}{a_{11}}x_k)^2-a_{11}
 (\sum\limits^n_{k=2}\frac{a_{1k}}{a_{11}}x_k)^2+\sum\limits_{i=2}^n
 \sum\limits_{j=2}^na_{ik}x_ix_k$
 
 Перейдем к новым координатам: $x'_1=x_1+\sum\limits^n_{k=2}\frac{a_{1k}}
 {a_{11}}x_k$, $x'_k=x_k$ для $k>1$.
 Это преобразование приведет к матрице перехода
 $$C_1=\begin{pmatrix}1&-\frac{a_{12}}{a{11}}&\ldots&-\frac{a_{1n}}{a_{11}}
 \\0&1&&0\\\vdots&&\ddots&\\0&\ldots&0&1\end{pmatrix}$$
 Таким образом в новом базисе $\mathcal A(x)=g(x_1,...,x_n)=a_{11}x_1'^2+
 h(x'_2,...,x'_n)$,
 $$A_1=C_1^TA_eC_1=\begin{pmatrix}a_{11}&0&\ldots&0\\0&a'_{22}&\ldots&a'_{2n}
 \\\vdots&\vdots&\ddots&\vdots\\0&a'_{n2}&\ldots&a'_{nn}\end{pmatrix}$$
 Заметим, что в этой матрице $\Delta_1=a_{11}$, $a'_{22}=\frac{\Delta_2}
 {\Delta_1}$
 
 \textbf{2.} Шаг 2 основан на том, что $a_{22}\ne0$, и состоит в применении 
 действий первого шага к квадратичной форме $h(x'_2...x'_n)$, т.е. в выделении
 полного квадрата по переменной $x'_2$:
 $$x''_2=x'_2+\sum\limits_{k=3}^n\frac{a'_{2k}}{a'_{22}}\cdot x'_k,~x''_j=
 x'_j,~j\in\{3..n\}$$
 Тогда квадратичная форма примет следующий вид: $\mathcal A(x)=a_{11}x'^2_1
 +a'_{22}x''^2_2+v(x''_3,...,x''_n)$,
 $$A_2=C_2^TA_1C_2=\begin{pmatrix}a_{11}&0&0&\ldots&0\\0&a'_{22}&0&\ldots&0\\
 0&0&a''_{33}&\ldots&a''_{3n}\\\vdots&\vdots&\vdots&\ddots&\vdots\\0&0&a''
_{n3}&\ldots&a''_{nn}\end{pmatrix}$$
 $a''_{33}=\frac{\Delta_3}{\Delta_2}\ne0$.
 
Итак, повторяя этот процесс $n-1$ раз, получим диагональную матрицу 
квадратичной формы $A_{n-1}=diag(\lambda_1...\lambda_n)$, 
$\lambda_k=\frac{\Delta_k}{\Delta_{k-1}}$, при этом мы предполагаем, что все
миноры не равны нулю. 
 
\textbf{3}. Рассмотрим случай, когда какой-нибудь минор $\Delta_k=0$. 
Тогда после k-того шага матрица квадратичной формы имеет вид:
$$A_{k-1}=diag(a_{11},a'_{22}...,a_{k-1,k-1}^{(k-r)},\boxed{B})$$
где матрица В равна 
$$B=\begin{pmatrix}a_{kk}&...&a_{kn}\\\vdots&\ddots&\vdots\\a_{nk}&...&a_{nn}
\end{pmatrix}$$
Пусть $B\ne0$. Имеем 2 случая:\\
1. Если $a_{kk}\ne0$, снова идем по алгоритму Лагранжа\\
2. Если $a_{kk}=0$, то:\\
 
а) Если $a_{jj}=\ne0,~j>k$, то произвести замену
$x'_k=x_j,~x'_j=x_k,~x'_e=x_e$, то есть поменять одновременно $k$-ые и $j$-ые 
строки и столбцы. Далее снова переходим к алгоритму Лагранжа.
 
 б) Если все следующие диагональные элементы равны нулю: $a_{ii}=0,~i>k$, то,
 поскольку В ненулевая, найдется ненулевой элемент $a_{lj},~l\ne j,~l,j>k,l\ne
 k$. Это означает, что в квадратичной форме отсутствуют слагаемые $x^2_k,.
 .,x^2_n$, но присутствуют члены типа $2a_{lj}x_lx_j$. Перейдем к новым 
 координатам $x_l=x'_l+x'_j,~x_i=x'_l-x'_j,~x'_s=x_s~\forall s\ne k,j$. Тогда 
 в квадратичной форме появятся $x'^2_l$ и $x'^2_j$. $\square$
 


 \begin{theor}
 Если в матрице квадратичной формы ранга r первые r миноров не равны нулю, то 
 существует базис е, в котором матрица квадратичной формы имеет вид
 \end{theor}
 $$A_e=diag(\lambda_1...\lambda_r,0...0),~\lambda_k=\frac{\Delta_k}
 {\Delta_{k-1}}$$
 \textbf{Доказательство} следует из предыдущей теоремы. Используя метод 
 Лагранжа, получаем матрицу $A_e=diag(\lambda_1,...,\lambda_r,\boxed{C})$, и 
 посокльку $rkA_e=rkA_r=r$, то матрица C - нулевая. Формулы $\lambda_k=
 \frac{\Delta_k}{\Delta_{k-1}}$ называются \textbf{формулами Якоби}. $\square$ 
 
 \subsection{Квадратичные формы в вещественном пространстве}
 Ни канонический базис, ни канонический вид квадратичной формы не определены
 однозначно. Возникает вопрос: что у них общего? Очевидно, сохраняется ранг,
 то есть число ненулевых $\lambda_i$. В вещественном пространстве можно также 
 говорить о постоянстве знаков коэффициентов канонической формы. 
 
 Пусть квадратичная форма была приведена к квадратичному виду в каноническом 
 базисе $\{e\}$: $\mathcal A(x)=\lambda_1x_1^2+...+\lambda_rx_r^2$, $\forall
 x=\sum\limits^n_{i=1}x_ie_i$, $dimV=n,~rk\mathcal A=r\leqslant n$. 
 \begin{defin}\makebox{}\\
\textbf{Положительный индекс инерции квадратичной формы}  $\pi$ -  число 
положительных коэффициентов квадратичной формы.\\\textbf{Отрицательный индекс
инерции квадратичной формы} $\nu=r-\pi$ - число отрицательных коэффициентов 
квадратичной формы.\\\textbf{Сигнатура квадратичной формы} $\sigma=\pi-\nu$ -
разность между положительным и отрицательным индексами инерции. \end{defin}
\begin{defin}
Квадратичная форма называется положительно определенной, если её сигнатура 
равна размерности пространства.
\end{defin}
Положительно определенная квадратичная форма, очевидно, для всех векторов 
принимает значения больше нуля: $\mathcal A(x)>0$.
\begin{theor} (закон инерции квадратичных форм)\\
 Положительный и отрицательный индексы инерции квадратичной формы не зависят 
 от выбора базиса.
\end{theor}
\textbf{Доказательство} \textit{нам не нужно в принципе} \copyright. Но мы-то
знаем, что этот вопрос есть в билетах, поэтому приведём доказательство.
 
Сначала отметим, что ранг формы есть максимальная размерность  подпространства,
на котором форма положительно определена. Очевидно, что она положительно 
определена на подпространстве $L(e_1,..,e_r)$. Пусть теперь $U$ - произвольное
подпространство,
 на котором форма положительно определена, и $W=L(e_{r+1},..,e_n)$. Так как
 $\mathcal A(x)\leqslant0$ при $x\in W$, то $U\cap W=0$. Отсюда следует, что
 $dimU\leqslant r$. Значит, индексы инерции не зависят от выбора базиса.
 $\square$
 \begin{defin}
 Обозначим число совпадений и перемен знаков в последовательности миноров 
 $\Delta_0,...,\Delta_k$ как $P(\Delta_0,...,\Delta_k)$ и $V(\Delta_0,...,
 \Delta_k)$ соответственно 
 \end{defin}
 \begin{theor}\label{jacobi_rule}
 (Сигнатурное правило Якоби)\\
 Пусть $\Delta_k$ - минор k-того порядка матрицы квадратичной формы ранга r, 
 и $\Delta_k\ne0~\forall k$. Тогда $\pi=P(\Delta_0,...\Delta_r)$, $\nu=
 V(\Delta_0,...,\Delta_r)$ 
 \end{theor}
 \textbf{Доказательство} следует из формулы Якоби, так как если $\lambda_k>0$,
 то $sgn\Delta_k=sgn\Delta_{k-1}$. $\square$
 \subsection{Знакоопределенные квадратичные формы}
 \begin{defin}
 Квадратичная форма называется положительно (отрицательно) определенной, если
 для любого ненулевого вектора принимает только положительные (отрицательные)
 значения.
 \end{defin}
 Все остальные квадратичные формы, для которых на разных векторах получаются
 разные знаки $\mathcal A(x)>0$ и $\mathcal A(y)<0$ - знакопеременные. 

\textbf{Пример.} Скалярный квадрат $\mathcal A(x)=(x,x)$ - положительно 
определенная квадратичная форма в $\mathbb R^n$.
\begin{theor}\label{opred_indexs}
Квадратичная форма $\mathcal A(x)$ является положительно (отрицательно) 
определенно, когда её положительный (отрицательный) индекс инерции совпадает
с размерностью пространства.
\end{theor}
\textbf{Доказательство.} Приведем доказательство для положительных форм. 
Пусть $\{e\}$ - канонический базис формы $\mathcal A(x)$, $\lambda_i$ - 
канонические коэффициенты, то есть $\mathcal A(x)=\sum\lambda_ix_i^2$\\
Необходимость. Если форма положительно определена, то $\mathcal A(e_i)>0$. 
Так как $\mathcal A(e_i)=\lambda_i$, то все $\lambda_i$ больше нуля. Значит,
индекс инерции положителен.\\
Достаточность. Пусть все $\lambda_i>0$. Тогда $\mathcal A(x)=
\sum\lambda_ix_i^2$, то есть форма положительно определена. \\
Для отрицательных форм доказательство точно такое же, только заменяем 
$\mathcal A(x)$ на $-\mathcal A(x)$. $\square$\\
\textbf{Следствие.} Определитель матрицы положительно определенной квадратичной
формы всегда положителен. 
Переходя к другому базису $\{f\}$: $|\mathcal A_f|=\prod\lambda_i|C|^2>0$,
поскольку $A_f=C^TA_eC$.
\begin{theor}
(критерий Сильвестра)\\
Квадаратичная форма $\mathcal A(x)$ является положительно (отрицательно) 
определенной тогда и только тогда, когда угловые миноры $\Delta_k$ матрицы 
формы в любом базисе положительны (чередуют знаки начиная с отрицательного:
$\Delta_k=a_{11}<0,~\Delta_2>0...$) 
\end{theor}
\textbf{Доказательство}. Необходимость. Пусть форма является положительно 
определенной, $A_e$ - её матрица в произвольном базисе $\{e\}$. Рассмотрим
подпространство $L_k=L(e_1,...,e_k)$, натянутое на первые $k$ векторов базиса.
Очевидно, что для всех  $x\in L_k$, $\mathcal A(x)>0$. Следовательно, $A_k$ 
имеет положительный определитель. Но $|A_k|$ это и есть $\Delta_k$. 
Следовательно, все $\Delta_k>0$ \\
Достаточность вытекает из теорем \ref{jacobi_rule} и \ref{opred_indexs}.\\
Для отрицательно определенных форм: рассмотрим $\mathcal A(x)$ с минорами
$\delta_k$. Если форма отрицательно определена, то все угловые миноры
$-\mathcal A(x)$ больше нуля: $(-1)^k\Delta_k>0$. Далее очевидно. $\square$ \\
Заметим, что если все угловые миноры отрицательны, то форма знакопеременная.\\
\textbf{Следствие.} Если квадратичная форма положительно определена в 
евклидовом пространстве, то все скалярные произведения исчерпываются 
билинейными формами, полярными к таким квадратичным формам в вещественном
пространстве. Из любой такой формы мы можем сделать скалярное произведение,
что сейчас и покажем.
\begin{theor}
Пусть $V=\mathbb R^n$. Отображение $\mathcal A\colon V\times V\to\mathbb R$ 
является скалярным произведением в пространстве V тогда и только тогда, когда
оно является билинейной формой, полярной к положительно определенной
квадратичной форме. 
\end{theor}
\textbf{Доказательство}. Необходимость следует из следствия критерия Сильвестра.
Покажем достаточность. Пусть $\mathcal A(x,y)$ - билинейная форма, полярная 
к положительно определенной квадратичной форме $\mathcal A(x)$. Матрицы этих 
форм совпадают. Тогда отображениие $\mathcal A\colon V\times V\to\mathbb R$, 
заданное как $\mathcal A(x,y)$, удовлетворяет аксиомам скалярного произведения.
$\square$\\
\textbf{Замечание}. Матрица билинейной формы, задающей скалярное проиведение,
совпадает с матрицей Грама базисных векторов: $A_e=\Gamma(e_1...e_n)$.
\subsection{Квадратичные формы в комплексном пространстве}
Аналогом билинейных форм форм в коплексном пространстве являются комплексные
билинейные формы. Иногда их называют полуторалинейными, почему - сейчас выясним.
\begin{defin}
Отображение $\mathcal A\colon V\times V\to\mathbb C$
называют комплексной билинейной (полуторалинейной) формой в пространстве V,
если для всех векторов выыполняются аксиомы
\end{defin}
1. $\mathcal A(x+y,z)=\mathcal A(x,z)+\mathcal A(y,z)$\\
2. $\mathcal A(ax,y)=a\mathcal A(x,y)$\\
3. $\mathcal A(x,y+z)=$\\
4. $\mathcal A(x,\alpha y)=\overline{\alpha}\mathcal A(x,y)$\\
Отличие от вещественного случая только в п.4
\begin{defin}
Форма эрмитова, если $\mathcal A(x,y)=\overline{\mathcal A(x,y)}$
\end{defin}
\textbf{Примеры}. Скалярное произведение в унитарном пространстве является
эрмитовой комплексной билинейной формой. \\
В $V=\mathbb C^n$ отображение $\mathcal A\colon V\times V\to\mathbb C$, 
определенное как $\mathcal A(x,y)=\sum_i\sum_ja_{ij}x_i\overline{y_j}$ -
комплексная билинейная форма ($a_{ij}=\mathcal A(e_i,e_j)$ - комплексные 
коэффициенты). Это выражение дает общий вид полуторалинейной формы в базисе 
$\{e\}$.

Многое из того, что касается вещественных форм, есть частный случай 
полуторалинейных форм, например:

1. Компактный (векторный) вид полуторалинейной формы: $\mathcal 
A(x,y)=X_e^TA_e\overline{Y_e}$ или $\mathcal A(x,y)=Y_e^HA_e^HX_E$

2. Переход между базисами $A_f=C^TA_E\overline{C}$

3. Эрмитовость формы эквивалентна эрмитовости её матрицы в любом базисе.
\begin{theor}\label{hermite_form}
Полуторалинейная форма является эрмитовой тогда и только тогда, когда её 
квадратичная форма вещественна для любого (комплексного) вектора.
\end{theor}
\textbf{Доказательство.} Необходимость. Пусть $\mathcal A(x,y)$ - эрмитова. 
Тогда $\mathcal A(x,x)=\overline{\mathcal A(x,x)}$, поэтому её значение
вещественно. \\
Достаточность. Пусть $\mathcal A(x,x)\in\mathbb R$. Достаточность следует из 
равенства $$\mathcal A(x,y)=\frac14(\mathcal A(x+y,x+y)-\mathcal A(x-y,x-y)
+i\mathcal A(x+iy,x+iy)-i\mathcal A(x-iy,x-iy))\quad\square$$

\subsection{Эрмитовы (квадратичные) формы}
\begin{defin}
Пусть $\mathcal A(x,y)$ - эрмитова полуторалинейная форма. Тогда $\mathcal
A\colon V\to\mathbb C,~x\mapsto\mathcal A(x,x)$ называется эрмитовой формой. 
\end{defin}
При этом комплексная форма $\mathcal A(x,y)$ является полярной к $\mathcal
A(x,x)$. Будем кратко обозначать эрмитову форму $\mathcal A(x)$.

\textbf{Cвойства эрмитовой формы}\\
1. Существет биекция между эрмитовыми полуторалинейными и эрмитовыми 
квадратичными формами.\\
2. Матрица эрмитовой формы в любом базисе эрмитова. \\
3. Общий вид эрмитовой формы $\mathcal A(x)=\sum_i\sum_ja_{ij}x_i
\overline{x_j}$ или $\mathcal A(x)=X_e^TA_e\overline{X_e}=X_e^HA_e^TX_e$\\
4. Канонический вид эрмитовой формы
$\mathcal A(x)=\lambda_1|x_1|^2+...+\lambda_r|x_r|^2$ где $r$ - ранг формы.\\
5. Метод Лагранжа приведения к каноническому виду применим с изменением:
$$\mathcal A(x)=g(x_1...x_n)=a_{11}x_1^2+2\sum\limits_{k=2}^na_{1k}x_1x_k+
\sum\limits_{i=2}^n\sum\limits^n_{k=2}a_{ik}x_ix_k=a_{11}\left\|x_1+\sum
\limits_{k=2}^n\frac{a_{1k}}{a_{11}}x_k\right\|^2+f(x_2,...x_n)$$\\
6. Остаются справедливыми формулы Якоби.\\
7. Как следует из теоремы \ref{hermite_form}, эрмитова квадратичная форма
принимает только вещественные значения, поэтому остаются справедливыми закон
инерции квадратичных форм, сигнатурное правило Якоби, критерий Сильвестра.\\
8. Отображение $\mathcal A\colon V\times V\to\mathbb C$ является скалярным
произведением тогда и только тогда, когда оно является полуторалинейной
формой, полярной к эрмитовой полуторалинейной форме. 

\subsection{Квадратичные формы в евклидовых и униатарных пространствах}
Ранее было отмечено, что ни канонический базис, ни канонический вид 
квадратичной формы не определены однозначно. При этом сохраняются количества 
положительных и отрицательных коэффициентов. В евклидовом (унитарном) 
пространстве положение иное, если рассматривать ортонормированный базис. 
\begin{theor}
Для любой квадратичной формы в евклидовом пространстве Е существует, и притом
единственный, симметрический оператор $\mathcal H\in L(E,E)$ такой, что:
\end{theor}
$$\mathcal A(x,x)=(\mathcal Hx,x)$$
\textbf{Доказательство.} Пусть выбран ортонормированный базис $\{e\}$ и
матрица формы $A_e$ в этом базисе. В силу
симметричности матрицы существует симметрический оператор $\mathcal H$, 
который в базисе $\{e\}$ имеет матрицу $A_e$. То есть, $\mathcal H_e=A_e$. 
Тогда для любого
вектора $x=\sum\limits_{i=1}^nx_ie_i$, 
$(\mathcal Hx)_e=\mathcal H_ex_e=A_ex_e$,
$x_e=(x_1,...x_n)^T$. Так как в ортонормированном базисе скалярное 
произведение векторов делается по правилу "строка на столбец", то $(\mathcal
Hx,x)=(A_ex_e,x_e)=x_e^TA_ex_e$. Но $\mathcal A(x,x)=x_e^TA_ex_e$. \\
Докажем единственность. Пусть $\mathcal H_1,~\mathcal H_2$ - два симметрически
х оператора, удовлетворяющих условию. Из этого равенства следует $((\mathcal
H_1-\mathcal H_2)x,x)=0$. Это означает, что оператор, равный разности
$\mathcal H_1-\mathcal H_2$, cимметрический, его собственные числа равны нулю.
Отсюда следует, что $\mathcal H_1=\mathcal H_2$ $\square$
\begin{theor}\label{privglavos}
Для любой квадратичной формы в евклидовом пространстве существует 
ортонормированный базис, в котором она имеет канонический вид. 
\end{theor}
\textbf{Доказательство}. По предыдущей теореме существует $\mathcal H$ - 
симметричный оператор со свойством $\mathcal A(x,x)=(\mathcal Hx,x)$. Если
ортонормированный базис $\{e\}$ составлен из собственных векторов оператора
$\mathcal H$, имеем $x=\sum x_ie_i$, $\mathcal A(x,x)=(\mathcal Hx,x)=
(\sum \lambda_ix_ie_i,\sum x_ie_i)=\sum \lambda_ix^2_i$, где $\lambda_i$ -
i-тое собственное значение оператора $\mathcal H$ $\square$

\textbf{Замечание.} Подобный метод построения ортонормированного базиса
фигурирует под названием "приведение квадратичной формы к главным осям". 
Теорема
\ref{privglavos} утверждает, что любая форма может быть приведена к такому 
виду. Причем, в отличие от метода Лагранжа, сохраняются канонические 
коэффиценты. Меняется только канонический базис, который определяется 
собственными векторами (поскольку вернее говорить о собственных 
подпространствах, имеется некторый произвол в выборе базиса). 
\begin{theor}
(о паре квадратичных форм)\\
Для любой пары квадратичных форм $\mathcal A,~\mathcal B$ в вещественном 
пространстве V, одна из которых положительно определена, сущетсвует общий 
базис, в котором обе квадратичные формы имеют канонический вид. 
\end{theor}
\textbf{Доказательство.} Пусть $\mathcal B(x,x)>0$. Тогда $\mathcal B(x,y)$
как билинейная форма, полярная к $\mathcal B(x,x)$, является скалярным 
произведением, то
есть $\mathcal B(x,y)=(x,y)$. Это означает, что в пространстве $V$ задано 
скалярное произведение, и оно является евклидовым. По теореме \ref{privglavos},
сущетсвует ортонормированный базис $\{e\}$, в котором $\mathcal A(x,x)=
\sum\lambda_ix_i^2$ ($\lambda_i$ - собственное значение матрицы формы
$\mathcal A(x,x)$ ).
Тогда для всех векторов $x=\sum x_ie_i$, имеем $\mathcal B(x,x)=(x,x)=\sum
x_i^2$. $\square$
\textbf{Замечание.} Укажем один из способов поиска общего ортонормированного
базиса. Пусть $A$ и $B$ - матрицы квадратичных форм $\mathcal A(x,x)$ и
$\mathcal B(x,x)$ соответсвенно в некотором базисе $f$, и пусть $e=fC$.
Тогда $C^TAC=\Lambda$, где $\Lambda=diag(\lambda_1,...\lambda_n)$ и $C^TBC=E$.
Следствие: $A=(C^T)^{-1}\Lambda C^{-1}$, $B=(C^T)^{-1}C^{-1}$. Отсюда
$B^{-1}=CC^T$ В итоге, $B^{-1}AC=C\Lambda$

Последнее равенство означает, что столбцы матрицы С, то есть координаты 
векторов искомого канонического базиса
$\{e\}$ в исходном базисе $\{f\}$ являются собственнными векторами матрицы
$B^{-1}A$, отвечающим собственным значениям $\lambda_i$. Таким образом, 
$\lambda_i$ являются корнями характеристического многочлена
$|B^{-1}A-\lambda I|=0$ или $|A-\lambda B|=0$, а векторы канонического базиса
- нетривиальными решениями СЛАУ $Ax=\lambda Bx$.

Эта теорема показывает, что положительно определенная форма $\mathcal B$
приводится к каноническому виду с коэффициентами, равными 1. Но на практике 
это не
требуется. Приведенный выше алгоритм применим и в том случае, если
$C^TBC=diag(\mu_1,...,\mu_n)$, то есть если вместо единичной матрицы на
диагонали стоят какие-то
числа. 

Вообще говоря, теоремы этого параграфа с очевидными изменениями (матрицы не
симметрические, а эрмитовы) распространяются на эрмитовы квадратичные формы
унитарных пространств. 

\subsection{Приложение: гиперповерхности порядка 2 в евклидовом пространстве}
\begin{defin}
Множество векторов евклидова пространства, удовлетворяющих уравнению 
$\mathcal A(x,x)+2g(x)+c=0$, называется гиперповерхностью второго порядка.
Здесь $\mathcal A(x,x)$ - квадратичная форма, $g(x)$ - линейная форма.
\end{defin}
Введем обозначения: $\{e\}$ - какой-то базис пространства $E$, $A=(a_{ij})$
- симметрическая матрица квадратичной формы в этом базисе, $b_i=g(e_i)$ -
коэффициенты линейной формы $g$ и $x=\sum x_ie_i$. В них уравнение перепишем
в виде
$$\sum_i\sum_ja_{ij}x_ix_j+2\sum_i b_ix_i+c=0$$
или в матричной форме $$x^T_eAx_e+2b^Tx_e+c=0$$
Проведем исследование гиперповерхности второго порядка в $n$-мерном 
евклидовом пространстве $E$. 

Пусть $\{e\}$ - ортонормированный базис, и пусть
гиперповерхность имеет вид $x^T_eAx_e+2b^Tx_e+c=0$, $A^T=A$.
Cделаем следующее:
1. Приведем форму $\mathcal A$ к главным осям, т.е. найдем ортонормированный
базис $\{f\}$, составленный из собственных векторов матрицы $A$, и укажем 
канонический вид этой формы:
$$\mathcal A(x,x)=\sum^r_{k=1}\lambda_k(x'_k)^2,~r=rkA$$
При переходе к новому базису, уравнение преобразуется:
$$\sum^r_{k=1}\lambda_kx'^2_k+2\sum^n_{k=1}b'_kx'_k+c=0$$
где $f=eC$, $x_e=Cx_f$, $x_f=(x'_1,...,x'_n)^T$ \\
2. Избавимся от переменных $x'_k$ в линейной части уравнения. Например, если
$\lambda_k\ne0$ для некоторого k, то
$\lambda_kx'^2_k+2b'_kx'_k=\lambda_k(x'_k+\frac{b'_k}{\lambda_k})^2-
\frac{b'^2_k}{\lambda_k}$. Положим $x''_k=x'_k+\frac{b'_k}{\lambda_k}$, и 
тогда уравнение перепишется в виде 
$$\sum\limits^r_{k=1}\lambda_kx''^2_k+2\sum\limits^n_{k=r+1}b'_kx''_k+c'=0$$
где $c'=c-\sum\limits_{k=1}^r\frac{b'^2_k}{\lambda_k}$\\
3. Исследуем полученное уравнение. Есть два случая:
\begin{itemize}
    \item При $k>r$, $b'_k=0$. Тогда уравнение не имеет линейной части и 
			приведено к нужному виду.
    \item Если все же линейная часть сохраняется, то сделаем ещё одно 
			преобразование. Построим его матрицу S. Пусть 
			$s=(b'_{r+1},...,b'_n)$ - ненулевой по условию вектор. Нормируем его:
    $s_1=(b'_{r+1},...,b'_n)/\sqrt{\sum\limits^n_{k=r+1}b'^2_k}$. Дополним
	этот вектор до ортонормированного базиса
    $\{s_{n-r}\}$ пространства $\mathbb R^{n-r}$. Тогда матрицa преобразования 
	имеет вид
    $$S=\begin{pmatrix}\boxed{E}&0&\ldots&0\\0&s_{1,r+1}&\ldots&s_{1,n}\\
	\vdots&\vdots&\ddots&\ldots\\0&s_{n-r,r+1}&\ldots&s_{n-r,n}\end{pmatrix}$$
    Эта матрица ортогональна, поскольку построена из столбцов координат 
	ортонормированного базиса. Значит, базис $\{f\}$ под её действием перейдет
	в ортонормированный базис. Проведем преобразование координат по правилу:\\
    $x'''_k=x''_k$ при $k$ от 1 до $r$;\\
    $x'''_k=\sum\limits^n_{k=r+1}b'_kx''_k/\sqrt{\sum\limits^n_{k=r+1}b'^2_k}$
	при $k=r+1$;\\
    $x'''_k=\sum\limits^n_{i=r+1}s_{k,i}x''_i$ при $k$ от $r+2$ до $n$;\\
    В этих координатах уранвение имеет канонический вид
    $$\sum\limits^r_{k=1}\lambda_kx'''^2_k+2x'''_{r+1}
	\sqrt{\sum\limits^n_{k=r+1}b'^2_k}+c'$$
    причем от $c'$ можно избавиться параллельным переносом. 
    
\end{itemize}
